{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75fa2b66-8cc1-4f2e-b697-21148ba9b4fb",
   "metadata": {},
   "source": [
    "# Meghanjali Chennupati (U30308400)\n",
    "\n",
    "##  In this notebook I would like to demonstrate building a Neural network model using MLP classifier , keras wide, deep neural network and hyperparameter tuning to my models and observe the metrics .\n",
    "\n",
    "##  I will also compare my results to the results of the previous models which I have done in assignment -1 and see the best model and metric for my data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752d6232-c900-44ad-8621-b6b0688f4269",
   "metadata": {},
   "source": [
    "# Description of the data set\n",
    "\n",
    "# Description of the data set:\n",
    "\n",
    "The data set is about CRYPTOTHERAPHY ANALYSIS.This data set provides patients characterstics after the tratment the level of cancer.\n",
    "It states whether the cancer level is benign(1) or malignant(0). This data set contains the following attributes:\n",
    "1. SEX- It indicates the gender of the patient whetehrthe patient is a male or female.(1=male,2=female)\n",
    "2. AGE- It indicates the age of the patient.\n",
    "3. Time- This column indicates the time for the treatment in seconds.\n",
    "4. Number of warts- This column indicates the numbe rof warts that are grown on a patients body. ( Warts are skin growths caused by a virus. The virus infects the top layer of skin, causing it to grow rapidly.Warts can grow anywhere on your body. Most warts go away on their own, but they may come back.)\n",
    "5. Type : It indicates the type of wart. ( there are mainly three types of warts . 1,2,3 ( common warts, flat,filtform)\n",
    "6. Area: The composition of wart .\n",
    "7. Result of the tratment: It indicates the level of cancer after tratment.\n",
    "\n",
    "The target variable is Result of the tratment. It is a binary classifier. benign(1) or malignant(0).\n",
    "This data set is a classification type of problem.\n",
    "The data set contains the instances of the 90 patients that are obtained from the results of cryptotheraphy treatment.\n",
    "\n",
    "Source of the data set: It is taken from the Mashhad University of Medical Sciences, Mashhad, Iran. Fahime Khozeimeh, MD, Pouran Layegh, Professor of Dermatology and Roohallah Alizadehsani, PhD student and Mohamad Roshanzamir, PhD candidate.\n",
    "\n",
    "It is published in UCI MACHINE LEARNING REPOSITORY: https://archive.ics.uci.edu/ml/datasets/Cryotherapy+Dataset+\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1015b3d-7d8b-4c0b-bc6a-e36f1c46f0a7",
   "metadata": {},
   "source": [
    "# Business problem statement and its purpose:\n",
    "1. The analysis of this data set will identify the results of the cancer treatment. It is a health care industry domain.\n",
    "2. Purpose :  This will helps the to explore and draw some inferences that may help the people to undergo the Cryotherapic treatment.\n",
    "3. It also helps the crytotheraphists to see the sttaistics and how well their treatment serves the people. How they can improve the level of treatment.\n",
    "4. It also helps to identify what age groups of patients  the treatment is getting malignant and what age groups of people is getting benign \n",
    "5. In this notebook I would like to do data preprocessing that is ready to apply modleing .\n",
    "6. For this assignment I would like to use the following algorithms (Discussed in class so far) to identify how well my models are trained and see how it performs of test data and if a new data is given it can able to predict the likelihood of results of level of tretament .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec420ca3-e91d-44e4-a580-a030110f1a96",
   "metadata": {},
   "source": [
    "## In my assignment-1 data prep notebook I already done the data preprocessing and saved them to files and I am using those files directly to load and fit my models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9dbef8-eabb-4a29-a5b2-33b4f09b7d92",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96170cf0-81b9-4dff-84df-095fe4e573af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffea556b-a019-4d5b-bac7-1440df82c36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdc572a-e1cb-4b0a-a157-667811b6e09b",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58bd5304-88e1-413d-b336-d074b1ae6e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"crypto_data_train_X.csv\")\n",
    "X_test = pd.read_csv(\"crypto_data_test_X.csv\")\n",
    "y_train = pd.read_csv(\"crypto_data_train_y.csv\")\n",
    "y_test = pd.read_csv(\"crypto_data_test_y.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c9c5b-474c-476d-92e5-00c2f243a17b",
   "metadata": {},
   "source": [
    "# Building a neural network model using Sk learn MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07ba236-fadf-41b7-8c81-852cb8636c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.25243384\n",
      "Validation score: 0.428571\n",
      "Iteration 2, loss = 1.06028859\n",
      "Validation score: 0.428571\n",
      "Iteration 3, loss = 0.95398818\n",
      "Validation score: 0.571429\n",
      "Iteration 4, loss = 0.70964856\n",
      "Validation score: 0.571429\n",
      "Iteration 5, loss = 0.77343455\n",
      "Validation score: 0.571429\n",
      "Iteration 6, loss = 0.77634682\n",
      "Validation score: 0.571429\n",
      "Iteration 7, loss = 0.65382765\n",
      "Validation score: 0.428571\n",
      "Iteration 8, loss = 0.61118733\n",
      "Validation score: 0.428571\n",
      "Iteration 9, loss = 0.64683433\n",
      "Validation score: 0.428571\n",
      "Validation score did not improve more than tol=0.000010 for 5 consecutive epochs. Stopping.\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 64.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model1 = MLPClassifier(\n",
    "    hidden_layer_sizes=(60,50,40), \n",
    "    activation = 'relu',\n",
    "    solver='adam',\n",
    "    alpha=0.0001, # Strength of the L2 regularization term\n",
    "    batch_size='auto',\n",
    "    learning_rate = 'constant',\n",
    "    learning_rate_init = 0.001,\n",
    "    max_iter=200,\n",
    "    tol=0.00001, \n",
    "    early_stopping = True,\n",
    "    n_iter_no_change = 5,\n",
    "    verbose=True\n",
    "    \n",
    ")\n",
    "_ = model1.fit(X_train, y_train)\n",
    "\n",
    "# Currently (version 1.2.2), MLPClassifier supports only the Cross-Entropy loss function.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8783137d-47a5-43c2-9d46-9775fbe8e44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2524338365377083,\n",
       " 1.0602885936287318,\n",
       " 0.9539881805889544,\n",
       " 0.7096485577454671,\n",
       " 0.7734345514350579,\n",
       " 0.7763468211359932,\n",
       " 0.6538276534182239,\n",
       " 0.6111873319746912,\n",
       " 0.646834328792195]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.loss_curve_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "493b8863-fe71-4edc-8a37-e88a9aabc0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b7827b1-388a-42bf-bf66-711e4f9e484e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6087    0.9333    0.7368        15\n",
      "           1     0.7500    0.2500    0.3750        12\n",
      "\n",
      "    accuracy                         0.6296        27\n",
      "   macro avg     0.6793    0.5917    0.5559        27\n",
      "weighted avg     0.6715    0.6296    0.5760        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88469a8e-f3c9-4d90-a178-a02f9b6f0a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model1.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f523ee84-2aa6-4041-a6b6-d63c1ebea8ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f06ec4-91ac-48e5-a10a-ed83af8badc6",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning using Randomised search cv for MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93ef521c-f88b-4f33-87b9-4d0fdbf5c387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n",
      "CPU times: total: 1.52 s\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [ (64,), (128,),(128,64), (64,128), (64,128,196), (196,128,64)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .0001, .0005, .001, .005],\n",
    "    'batch_size': [25, 50, 100],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.0005, 0.001, 0.005, 0.01],\n",
    "    'max_iter': [5000],\n",
    "    'tol': [0.000005, 0.00001, 0.00005],\n",
    "    'early_stopping':[True],\n",
    "    'n_iter_no_change':[5],\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator = MLPClassifier(), # a blank slate... RandomizedSearchCV will send parameters.\n",
    "    param_distributions=param_distributions, \n",
    "    cv=3, \n",
    "    n_iter=300,\n",
    "    scoring='f1_macro', # note that we could also choose any other scoring metric that is appropriate for a multi-class problem - such as f1_macro, f1_micro, f1_weighted, etc.\n",
    "    verbose=1, \n",
    "    n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "_ = random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41540086-e945-462b-a3a5-e3db7eb0690d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tol': 5e-05, 'solver': 'adam', 'n_iter_no_change': 5, 'max_iter': 5000, 'learning_rate_init': 0.005, 'learning_rate': 'constant', 'hidden_layer_sizes': (64,), 'early_stopping': True, 'batch_size': 25, 'alpha': 0.0001, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "model2 = random_search.best_estimator_\n",
    "\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec78816-fc39-4648-a8df-d775c1fc8560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.4000    0.5000        15\n",
      "           1     0.5000    0.7500    0.6000        12\n",
      "\n",
      "    accuracy                         0.5556        27\n",
      "   macro avg     0.5833    0.5750    0.5500        27\n",
      "weighted avg     0.5926    0.5556    0.5444        27\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 13.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd1b1b1-b291-494e-941b-ce55f40857a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d696f85-6010-4316-a522-548b6b7592b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3715458c-9a0e-4e57-a5d7-42c7534c5e9e",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning using grid search cv for MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8845107-f4ea-48c3-9b68-5fb4c5d7a13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 154 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "param_distributions = {\n",
    "    'hidden_layer_sizes': [(64,)],\n",
    "    'activation': ['tanh'],\n",
    "    'solver': ['sgd'],\n",
    "    'alpha': [0.0001],\n",
    "    'batch_size': [25],\n",
    "    'learning_rate': ['adaptive'],\n",
    "    'learning_rate_init': [0.005],\n",
    "    'max_iter': [5000],\n",
    "    'tol': [0.00005],\n",
    "    'early_stopping':[True],\n",
    "    'n_iter_no_change':[5],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = MLPClassifier(), # a blank slate... RandomizedSearchCV will send parameters.\n",
    "    param_grid=param_distributions, \n",
    "    cv=5,\n",
    "    scoring='f1_macro', # note that we could also choose any other scoring metric that is appropriate for a multi-class problem - such as f1_macro, f1_micro, f1_weighted, etc.\n",
    "    verbose=1, \n",
    "    n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cda3582-993f-4a53-8b51-1848f2a95f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 25, 'early_stopping': True, 'hidden_layer_sizes': (64,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.005, 'max_iter': 5000, 'n_iter_no_change': 5, 'solver': 'sgd', 'tol': 5e-05}\n"
     ]
    }
   ],
   "source": [
    "model2 = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "828c3801-160d-44f1-b7f5-c696db0f3bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.4000    0.1333    0.2000        15\n",
      "           1     0.4091    0.7500    0.5294        12\n",
      "\n",
      "    accuracy                         0.4074        27\n",
      "   macro avg     0.4045    0.4417    0.3647        27\n",
      "weighted avg     0.4040    0.4074    0.3464        27\n",
      "\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 16.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model2.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4bfb48e4-eb12-4cfb-92d8-2e3fa8a3761f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model2.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2546fb93-f061-48eb-b74e-f7e6e25e2da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAGwCAYAAABSAee3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqEElEQVR4nO3deXgUZdb38V8lkE6AdCBAQqIBgiK7gAFZ3GBUnKg8YXxHZUBFBB1ERZ6oMD7I4gIRncEoSAR8BC5HFF4VRMaNURA3xIRFBQTRAEGI4IDEJGSv9w+kXwMB0+nqdFfX98NV1zVV1VV1kkFOn3PfVWWYpmkKAADYUligAwAAAHVHIgcAwMZI5AAA2BiJHAAAGyORAwBgYyRyAABsjEQOAICNNQh0AL6oqqrS/v37FR0dLcMwAh0OAMBLpmnql19+UWJiosLC/FdblpSUqKyszOfzREREKDIy0oKIrGPrRL5//34lJSUFOgwAgI/y8vJ09tln++XcJSUliopuLlUU+3yuVq1aKTc3N6iSua0TeXR0tCRpV26eot3uAEcD+EfrAfcHOgTAb8zKMpVtW+z599wfysrKpIpiuTqPkMIj6n6iyjLlb1ussrIyErlVTrTTo91uuUnkCFGGL//wADZRL8OjDSJ9+u/JNIJzWpmtEzkAALVmSPLlC0OQTsUikQMAnMEIO774cnwQCs6oAABArVCRAwCcwTB8bK0HZ2+dRA4AcAZa6wAAINhQkQMAnIHWOgAAduZjaz1Im9jBGRUAAKgVKnIAgDPQWgcAwMaYtQ4AAIINFTkAwBlorQMAYGMh2lonkQMAnCFEK/Lg/HoBAABqhYocAOAMtNYBALAxw/AxkdNaBwAAFqMiBwA4Q5hxfPHl+CBEIgcAOEOIjpEHZ1QAAKBWqMgBAM4QoveRk8gBAM5Aax0AAAQbKnIAgDPQWgcAwMZorQMAYGMnKnJfFi+sW7dOgwcPVmJiogzD0IoVKzz7ysvLNXHiRHXr1k2NGzdWYmKibrnlFu3fv9/rH4tEDgCAHxQVFal79+6aM2fOKfuKi4u1ceNGTZ48WRs3btTrr7+unTt36r/+67+8vg6tdQCAM9Rzaz01NVWpqak17ouJidHq1aurbZs9e7YuvPBC7d27V61bt671dUjkAABnsGiyW0FBQbXNLpdLLpfLl8gkSUePHpVhGGratKlXx9FaBwDAC0lJSYqJifEsGRkZPp+zpKREf/vb3zRs2DC53W6vjqUiBwA4hI+t9V9r37y8vGrJ1tdqvLy8XEOHDlVVVZXmzp3r9fEkcgCAM1jUWne73V5XzadTXl6uG264Qbm5ufrggw/qdF4SOQAAAXAiiX/77bdas2aNmjdvXqfzkMgBAM5gGD7OWveumi8sLNSuXbs867m5udq8ebNiY2OVmJioP//5z9q4caNWrVqlyspK5efnS5JiY2MVERFR6+uQyAEAzlDPt59lZ2dr4MCBnvX09HRJ0ogRIzRt2jStXLlSktSjR49qx61Zs0YDBgyo9XVI5AAA+MGAAQNkmuZp959pnzdI5AAAZ+ClKQAA2FiIvjSFRA4AcIYQrciD8+sFAACoFSpyAIAz0FoHAMDGaK0DAIBgQ0UOAHAEwzBkhGBFTiIHADhCqCZyWusAANgYFTkAwBmMXxdfjg9CJHIAgCPQWgcAAEGHihwA4AihWpGTyAEAjkAiBwDAxkI1kTNGDgCAjVGRAwCcgdvPAACwL1rrAAAg6FCRAwAc4fhbTH2pyK2LxUokcgCAIxjysbUepJmc1joAADZGRQ4AcIRQnexGIgcAOEOI3n5Gax0AABujIgcAOIOPrXWT1joAAIHj6xi5bzPe/YdEDgBwhFBN5IyRAwBgY1TkAABnCNFZ6yRyAIAj0FoHAABBh4ocAOAIoVqRk8gBAI4Qqomc1joAADZGRQ4AcIRQrchJ5AAAZwjR289orQMAYGNU5AAAR6C1DgCAjZHIAQCwsVBN5IyRAwBgY1TkAABnCNFZ6yRyAIAj0FoHAABBh4ocv2vWwne1as0WfbvnR0W6GurC89tp2t1pat82PtChAXXSv+c5uufmK9S9Y2sltIzR8Pvn660Pv/Tsn3j71bpu0AU6K76ZyssrtfmbvXps7pvK2bongFHDV1TkcKxPN+7S6Osv1Xsv3K/X59ytispKXXfPHBUdKw10aECdNIpy6eudP2jCk8tq3P/d3oOa8OT/1UV/maHU22dp7/7Den3O3WretEk9RworGTI8ybxOS5AOkgc8kc+dO1fJycmKjIxUSkqKPvroo0CHhJO8OvsuDRvcV53OSVC3887Ws1Nu0r78I9q8PS/QoQF18u9Pt2n6c6u0as2WGve/+m62PtywQ3t++I+++T5fD2W+LneTKHVpn1jPkQK/L6CJfOnSpRo/frwmTZqkTZs26ZJLLlFqaqr27t0byLDwOwoKSyRJzdyNAhwJ4H8NG4RrxJ8u0tFfivX1zh8CHQ584FM17mNb3p8CmshnzZqlUaNGafTo0erUqZMyMzOVlJSkrKysQIaFMzBNU5Oeek19e5yjzudSnSB0XXVxV+V9+A/lf/KU7vzLQP3p7jk6fLQo0GHBF4YFSxAKWCIvKytTTk6OBg0aVG37oEGD9Omnn9Z4TGlpqQoKCqotqF8PPLFMW3ft1/OP3RroUAC/+ih7py4dnqGrRs3S+59t08IZt6lFM8bIEXwClsh/+uknVVZWKj6++szn+Ph45efn13hMRkaGYmJiPEtSUlJ9hIpfTXhymd5e95XezBqns+KbBTocwK+KS8qUu+8nZX+9W+MeW6KKyirdnNY/0GHBB7TW/eTkX4xpmqf9ZT344IM6evSoZ8nLY7JVfTBNUw88sUyr1mzRyqxxanNWi0CHBNQ7wzAU0ZA7du0sVBN5wP5WtmjRQuHh4adU3wcPHjylSj/B5XLJ5XLVR3j4jftnLtOr72Zryd/vUJNGkfrxp+NDGu4mkYqKjAhwdID3GkdFKDmppWe9TWJzdT3vLP18tFiHjxbpvtuu0tvrvtKPPx1Vs5jGGvXnS5UY11RvvL8xgFHDV4ZxfPHl+GAUsEQeERGhlJQUrV69Wn/6058821evXq20tLRAhYUavPDa8VsCrx3zdLXtz065ScMG9w1ESIBPenRqo1Xz7vWsz0j/P5KkJavWKz3jFbVvG6+h1/RR86aNdfhosTZt26Or73hK33xf87AfEEgB7ROlp6fr5ptvVq9evdSvXz/Nnz9fe/fu1ZgxYwIZFk5y5Is5gQ4BsNQnG79Vs953n3b/LROer8doUF+OV+S+PNnNu8+vW7dOTz75pHJycnTgwAEtX75cQ4YM8ew3TVMPP/yw5s+fryNHjqhPnz569tln1aVLF6+uE9Ax8htvvFGZmZl65JFH1KNHD61bt05vvfWW2rRpE8iwAAChyPj/7fW6LN7eflZUVKTu3btrzpyai6EnnnhCs2bN0pw5c/TFF1+oVatWuvLKK/XLL794dZ2Az9wYO3asxo4dG+gwAACwVGpqqlJTU2vcZ5qmMjMzNWnSJF133XWSpMWLFys+Pl5LlizRX//611pfJ+Cz1gEAqA9WzVo/+XkmpaXev3ciNzdX+fn51Z6l4nK5dNlll532WSqnQyIHADiCL2313854T0pKqvZMk4yMDK9jOXHHljfPUjmdgLfWAQCwk7y8PLndbs+6L7dFe/MsldMhkQMAHCEszFBYWN1nrZu/Hut2u6sl8rpo1aqVpOOVeUJCgmf7mZ6lcjq01gEAjmBVa90KycnJatWqlVavXu3ZVlZWpg8//FD9+3v3KGAqcgAA/KCwsFC7du3yrOfm5mrz5s2KjY1V69atNX78eM2YMUPt27dX+/btNWPGDDVq1EjDhg3z6jokcgCAI/j6vHRvj83OztbAgQM96+np6ZKkESNGaNGiRZowYYKOHTumsWPHeh4I89577yk6Otqr65DIAQCOUN/PWh8wYIBM0zzD+QxNmzZN06ZNq3tQIpEDAByivivy+sJkNwAAbIyKHADgCKFakZPIAQCOEKrvI6e1DgCAjVGRAwAcwZCPrXVv32NaT0jkAABHoLUOAACCDhU5AMARmLUOAICN0VoHAABBh4ocAOAItNYBALCxUG2tk8gBAI4QqhU5Y+QAANgYFTkAwBl8bK0H6YPdSOQAAGegtQ4AAIIOFTkAwBGYtQ4AgI3RWgcAAEGHihwA4Ai01gEAsDFa6wAAIOhQkQMAHCFUK3ISOQDAERgjBwDAxkK1ImeMHAAAG6MiBwA4Aq11AABsjNY6AAAIOlTkAABHMORja92ySKxFIgcAOEKYYSjMh0zuy7H+RGsdAAAboyIHADgCs9YBALCxUJ21TiIHADhCmHF88eX4YMQYOQAANkZFDgBwBsPH9niQVuQkcgCAI4TqZDda6wAA2BgVOQDAEYxf//hyfDAikQMAHIFZ6wAAIOhQkQMAHIEHwgAAYGOhOmu9Von8mWeeqfUJx40bV+dgAACAd2qVyJ966qlancwwDBI5ACAoheprTGuVyHNzc/0dBwAAfhWqrfU6z1ovKyvTjh07VFFRYWU8AAD4xYnJbr4swcjrRF5cXKxRo0apUaNG6tKli/bu3Svp+Nj4448/bnmAAADg9LxO5A8++KC2bNmitWvXKjIy0rP9iiuu0NKlSy0NDgAAq5xorfuyBCOvbz9bsWKFli5dqr59+1ZrM3Tu3FnfffedpcEBAGCVUJ3s5nVFfujQIcXFxZ2yvaioKGjHDwAACFVeJ/LevXvrX//6l2f9RPJesGCB+vXrZ11kAABYyLBgCUZet9YzMjL0xz/+Udu2bVNFRYWefvppbd26VZ999pk+/PBDf8QIAIDPQvURrV5X5P3799cnn3yi4uJinXPOOXrvvfcUHx+vzz77TCkpKf6IEQAAnEadnrXerVs3LV682OpYAADwm/p+jWlFRYWmTZuml156Sfn5+UpISNCtt96qhx56SGFh1r18tE6JvLKyUsuXL9f27dtlGIY6deqktLQ0NWjAO1gAAMGpvlvrM2fO1HPPPafFixerS5cuys7O1siRIxUTE6N77723znGczOvM+/XXXystLU35+fnq0KGDJGnnzp1q2bKlVq5cqW7dulkWHAAAwaagoKDausvlksvlOuVzn332mdLS0nTNNddIktq2bauXX35Z2dnZlsbjdW0/evRodenSRfv27dPGjRu1ceNG5eXl6fzzz9cdd9xhaXAAAFjJiofBJCUlKSYmxrNkZGTUeK2LL75Y77//vnbu3ClJ2rJliz7++GNdffXVlv5MXlfkW7ZsUXZ2tpo1a+bZ1qxZM02fPl29e/e2NDgAAKxiVWs9Ly9Pbrfbs72malySJk6cqKNHj6pjx44KDw9XZWWlpk+frr/85S91jqEmXifyDh066Mcff1SXLl2qbT948KDOPfdcywIDAMBKVk12c7vd1RL56SxdulT//Oc/tWTJEnXp0kWbN2/W+PHjlZiYqBEjRtQ9kJPUKpH/djxgxowZGjdunKZNm6a+fftKktavX69HHnlEM2fOtCwwAADs7IEHHtDf/vY3DR06VNLxO7727NmjjIyM+k/kTZs2rdaOME1TN9xwg2ebaZqSpMGDB6uystKy4AAAsEp9z1ovLi4+5Taz8PBwVVVV1TmGmtQqka9Zs8bSiwIAUN98fcyqt8cOHjxY06dPV+vWrdWlSxdt2rRJs2bN0m233eZDFKeqVSK/7LLLLL0oAAChbvbs2Zo8ebLGjh2rgwcPKjExUX/96181ZcoUS69T5ye4FBcXa+/evSorK6u2/fzzz/c5KAAArFbfrzGNjo5WZmamMjMz63zN2vA6kR86dEgjR47U22+/XeN+xsgBAMHo5PvB63J8MPL6gTDjx4/XkSNHtH79ekVFRemdd97R4sWL1b59e61cudIfMQIAgNPwuiL/4IMP9MYbb6h3794KCwtTmzZtdOWVV8rtdisjI8PzKDoAAIIJrzH9VVFRkeLi4iRJsbGxOnTokKTj98dt3LjR2ugAALCIL49n9bUt709eJ/IOHTpox44dkqQePXpo3rx5+uGHH/Tcc88pISHB8gABAMDped1aHz9+vA4cOCBJmjp1qq666iq99NJLioiI0KJFi6yODwAAS9T3rPX64nUiHz58uOd/9+zZU7t379Y333yj1q1bq0WLFpYGBwCAVUJ11nqd7yM/oVGjRrrgggusiAUAAL8J1clutUrk6enptT7hrFmz6hwMAADwTq0S+aZNm2p1skB9WzlcWKbysLLf/yBgQ31GWPvuYiCYVJQU6ZMHF9TLtcJUhxneJx0fjHhpCgDAEUK1tR6sXzAAAEAt+DzZDQAAOzAMKYxZ6wAA2FOYj4ncl2P9idY6AAA2RkUOAHAEJrv9xosvvqiLLrpIiYmJ2rNnjyQpMzNTb7zxhqXBAQBglROtdV+WYOR1Is/KylJ6erquvvpq/fzzz6qsrJQkNW3aVJmZmVbHBwAAzsDrRD579mwtWLBAkyZNUnh4uGd7r1699NVXX1kaHAAAVgnV15h6PUaem5urnj17nrLd5XKpqKjIkqAAALBaqL79zOuKPDk5WZs3bz5l+9tvv63OnTtbERMAAJYLs2AJRl5X5A888IDuuusulZSUyDRNbdiwQS+//LIyMjL0/PPP+yNGAABwGl4n8pEjR6qiokITJkxQcXGxhg0bprPOOktPP/20hg4d6o8YAQDwGe8j/43bb79dt99+u3766SdVVVUpLi7O6rgAALBUmHwcI1dwZnKfHgjTokULq+IAAAB14HUiT05OPuPTbb7//nufAgIAwB9orf9q/Pjx1dbLy8u1adMmvfPOO3rggQesigsAAEuF6ktTvE7k9957b43bn332WWVnZ/scEAAAqD3LbotLTU3Va6+9ZtXpAACw1PH3kRt1XkKmtX46r776qmJjY606HQAAlmKM/Fc9e/asNtnNNE3l5+fr0KFDmjt3rqXBAQCAM/M6kQ8ZMqTaelhYmFq2bKkBAwaoY8eOVsUFAIClmOwmqaKiQm3bttVVV12lVq1a+SsmAAAsZ/z6x5fjg5FXk90aNGigO++8U6Wlpf6KBwAAvzhRkfuyBCOvZ6336dNHmzZt8kcsAADAS16PkY8dO1b33Xef9u3bp5SUFDVu3Lja/vPPP9+y4AAAsIrjx8hvu+02ZWZm6sYbb5QkjRs3zrPPMAyZpinDMFRZWWl9lAAA+MgwjDM+Yrw2xwejWifyxYsX6/HHH1dubq4/4wEAAF6odSI3TVOS1KZNG78FAwCAvzi+tS4Fb1sBAIDfw5PdJJ133nm/m8wPHz7sU0AAAKD2vErkDz/8sGJiYvwVCwAAfnPi5Se+HB+MvErkQ4cOVVxcnL9iAQDAb0J1jLzWD4RhfBwAgODj9ax1AABsycfJbkH6qPXaJ/Kqqip/xgEAgF+FyVCYD9nYl2P9yetHtAIAYEehevuZ1y9NAQAAwYOKHADgCKE6a51EDgBwhFC9j5zWOgAANkZFDgBwhFCd7EYiBwA4Qph8bK0H6e1ntNYBALAxKnIAgCPQWgcAwMbC5FsbOlhb2MEaFwAAtvfDDz/opptuUvPmzdWoUSP16NFDOTk5ll6DihwA4AiGYfj0Jk9vjz1y5IguuugiDRw4UG+//bbi4uL03XffqWnTpnWOoSYkcgCAIxjy7QVmJ44tKCiott3lcsnlcp3y+ZkzZyopKUkLFy70bGvbtq0PEdSM1joAwBFOPNnNl0WSkpKSFBMT41kyMjJqvN7KlSvVq1cvXX/99YqLi1PPnj21YMECy38uKnIAALyQl5cnt9vtWa+pGpek77//XllZWUpPT9f//M//aMOGDRo3bpxcLpduueUWy+IhkQMAHMOKO8jcbne1RH46VVVV6tWrl2bMmCFJ6tmzp7Zu3aqsrCxLEzmtdQCAI5y4j9yXxRsJCQnq3LlztW2dOnXS3r17LfypSOQAAPjFRRddpB07dlTbtnPnTrVp08bS69BaBwA4Qn3ffvbf//3f6t+/v2bMmKEbbrhBGzZs0Pz58zV//vw6x1ATKnIAgCOEWbB4o3fv3lq+fLlefvllde3aVY8++qgyMzM1fPhwS36eE6jIAQDwk2uvvVbXXnutX69BIgcAOEJ9t9brC4kcAOAIVj3ZLdgwRg4AgI1RkQMAHIHWOgAANhaq7yMnkQMAHCFUK/Jg/YIBAABqgYocAOAIoTprnUQOAHCEurz45OTjgxGtdQAAbIyKHADgCGEyFOZDg9yXY/2JRA4AcARa6wAAIOhQkQMAHMH49Y8vxwcjEjkAwBForQMAgKBDRQ4AcATDx1nrtNYBAAigUG2tk8gBAI4QqomcMXIAAGyMihwA4AjcfgYAgI2FGccXX44PRrTWAQCwMSpyAIAj0FoHAMDGmLUOAACCDhU5AMARDPnWHg/SgpxEDgBwBmatAwCAoENFjt/10hufaMnKT7Uv/7AkqX3bVrrnlkG6rE+nAEcGWCeqYbhu6dNa/dvFqmmjhvruUJGe+yhXOw8WBjo0WIRZ63CsVi2b6oHbr1Gbs1pIkl5/N1tjHnpBb8y/T+cltwpwdIA1xv/hXLWNbaQn//2t/lNUpss7tFRGWhfdsWST/lNUFujwYAFmrfvBunXrNHjwYCUmJsowDK1YsSKQ4eA0Lu/fRQP6dlZyUpySk+J03+ir1SgqQpu37Q50aIAlIsLDdPE5zfW/n+7W1/sLdOBoif65IU/5BSW6titfVkOFYcESjAKayIuKitS9e3fNmTMnkGHAC5WVVVr1wSYVl5SpZ5e2gQ4HsER4mKHwMENllVXVtpdVVqlLojtAUQG1E9DWempqqlJTU2v9+dLSUpWWlnrWCwoK/BEWarDj+/26/q5nVFpWoUZREcp6ZKTat6VSQWg4Vl6pbQcKNKx3kvYeOaafi8s0oH1LdYiP1v6fSwIdHiwSJkNhPvTHw4K0JrfVrPWMjAzFxMR4lqSkpECH5BjJSXFa+fx9enXuvRqW1l8PPP6yvt2dH+iwAMs8ufpbSdKSkb315p39ldY9QWt3HlKlaQY4MlglVFvrtprs9uCDDyo9Pd2zXlBQQDKvJxENG6jtWS0lSd06JOmrb/K0+LV1euy+GwIcGWCNAwUlmrD8a7kahKlxRLgOF5frwas66McCKnIEN1slcpfLJZfLFegwIMk0pbLyykCHAViutKJKpRVVauIKV0rrpvrfT3cHOiRYxdeyOkhLclslcgTG3xf8S5f16aSEuKYqKi7Rqg826/Mtu/TCzDsCHRpgmZTWTSVJ+44cU2LTSI3u31b7jhzTe9sPBjYwWIb7yOFYPx35RffPeEkHDxcounGUOrZL0Asz79DFvToEOjTAMo0iwjWyXxu1aOJSYUmFPv7uP1q0fo8qqxgjR3ALaCIvLCzUrl27POu5ubnavHmzYmNj1bp16wBGht96fMLQQIcA+N1Hu/6jj3b9J9BhwJ98fCBMkBbkgU3k2dnZGjhwoGf9xES2ESNGaNGiRQGKCgAQikJ0iDywiXzAgAEyubUDAIA6Y4wcAOAMIVqSk8gBAI7ArHUAAGyMt58BAICgQ0UOAHCEEB0iJ5EDABwiRDM5rXUAAGyMihwA4AjMWgcAwMaYtQ4AAIIOFTkAwBFCdK4biRwA4BAhmslprQMAYGNU5AAARwjVWetU5AAARzgxa92Xpa4yMjJkGIbGjx9v2c9zAhU5AMARAjVE/sUXX2j+/Pk6//zzfbj66VGRAwDgJ4WFhRo+fLgWLFigZs2a+eUaJHIAgDMYFiySCgoKqi2lpaWnveRdd92la665RldccYWffigSOQDAIQwL/khSUlKSYmJiPEtGRkaN13vllVe0cePG0+63CmPkAAB4IS8vT26327Pucrlq/My9996r9957T5GRkX6Nh0QOAHAEq5617na7qyXymuTk5OjgwYNKSUnxbKusrNS6des0Z84clZaWKjw8vO7B/AaJHADgCPU5a/3yyy/XV199VW3byJEj1bFjR02cONGyJC6RyAEAsFx0dLS6du1abVvjxo3VvHnzU7b7ikQOAHCGEH3WOokcAOAIgX5E69q1a306/nS4/QwAABujIgcAOIJVs9aDDYkcAOAIITpETiIHADhEiGZyxsgBALAxKnIAgCMEeta6v5DIAQDO4ONktyDN47TWAQCwMypyAIAjhOhcNxI5AMAhQjST01oHAMDGqMgBAI7ArHUAAGwsVB/RSmsdAAAboyIHADhCiM51I5EDABwiRDM5iRwA4AihOtmNMXIAAGyMihwA4AiGfJy1blkk1iKRAwAcIUSHyGmtAwBgZ1TkAABHCNUHwpDIAQAOEZrNdVrrAADYGBU5AMARaK0DAGBjodlYp7UOAICtUZEDAByB1joAADYWqs9aJ5EDAJwhRAfJGSMHAMDGqMgBAI4QogU5iRwA4AyhOtmN1joAADZGRQ4AcARmrQMAYGchOkhOax0AABujIgcAOEKIFuQkcgCAMzBrHQAABB0qcgCAQ/g2az1Ym+skcgCAI9BaBwAAQYdEDgCAjdFaBwA4Qqi21knkAABHCNVHtNJaBwDAxqjIAQCOQGsdAAAbC9VHtNJaBwDAxqjIAQDOEKIlOYkcAOAIzFoHAABBh4ocAOAIzFoHAMDGQnSInEQOAHCIEM3kjJEDAOAHGRkZ6t27t6KjoxUXF6chQ4Zox44dll+HRA4AcATDgj/e+PDDD3XXXXdp/fr1Wr16tSoqKjRo0CAVFRVZ+nPRWgcAOEJ9T3Z75513qq0vXLhQcXFxysnJ0aWXXlr3QE5i60RumqYkqfCXXwIcCeA/FSXWfnsHgsmJv98n/j33p4KCAkuOP/k8LpdLLpfrd48/evSoJCk2NtanOE5mmPXx2/OTffv2KSkpKdBhAAB8lJeXp7PPPtsv5y4pKVFycrLy8/N9PleTJk1UWFhYbdvUqVM1bdq0Mx5nmqbS0tJ05MgRffTRRz7H8Vu2rsgTExOVl5en6OhoGcF6g1+IKSgoUFJSkvLy8uR2uwMdDmAp/n7XP9M09csvvygxMdFv14iMjFRubq7Kysp8Ppdpmqfkm9pU43fffbe+/PJLffzxxz7HcDJbJ/KwsDC/fYPDmbndbv6hQ8ji73f9iomJ8fs1IiMjFRkZ6ffr1OSee+7RypUrtW7dOr/kLFsncgAAgpVpmrrnnnu0fPlyrV27VsnJyX65DokcAAA/uOuuu7RkyRK98cYbio6O9ozRx8TEKCoqyrLrcB85vOJyuTR16tRajQkBdsPfb1gpKytLR48e1YABA5SQkOBZli5daul1bD1rHQAAp6MiBwDAxkjkAADYGIkcAAAbI5EDAGBjJHLU2ty5c5WcnKzIyEilpKRY/phBIFDWrVunwYMHKzExUYZhaMWKFYEOCag1EjlqZenSpRo/frwmTZqkTZs26ZJLLlFqaqr27t0b6NAAnxUVFal79+6aM2dOoEMBvMbtZ6iVPn366IILLlBWVpZnW6dOnTRkyBBlZGQEMDLAWoZhaPny5RoyZEigQwFqhYocv6usrEw5OTkaNGhQte2DBg3Sp59+GqCoAAASiRy18NNPP6myslLx8fHVtsfHx1vyWkAAQN2RyFFrJ7+6r6bX+QEA6heJHL+rRYsWCg8PP6X6Pnjw4ClVOgCgfpHI8bsiIiKUkpKi1atXV9u+evVq9e/fP0BRAQAkXmOKWkpPT9fNN9+sXr16qV+/fpo/f7727t2rMWPGBDo0wGeFhYXatWuXZz03N1ebN29WbGysWrduHcDIgN/H7Weotblz5+qJJ57QgQMH1LVrVz311FO69NJLAx0W4LO1a9dq4MCBp2wfMWKEFi1aVP8BAV4gkQMAYGOMkQMAYGMkcgAAbIxEDgCAjZHIAQCwMRI5AAA2RiIHAMDGSOQAANgYiRwAABsjkQM+mjZtmnr06OFZv/XWWzVkyJB6j2P37t0yDEObN28+7Wfatm2rzMzMWp9z0aJFatq0qc+xGYahFStW+HweAKcikSMk3XrrrTIMQ4ZhqGHDhmrXrp3uv/9+FRUV+f3aTz/9dK0f61mb5AsAZ8JLUxCy/vjHP2rhwoUqLy/XRx99pNGjR6uoqEhZWVmnfLa8vFwNGza05LoxMTGWnAcAaoOKHCHL5XKpVatWSkpK0rBhwzR8+HBPe/dEO/yFF15Qu3bt5HK5ZJqmjh49qjvuuENxcXFyu936wx/+oC1btlQ77+OPP674+HhFR0dr1KhRKikpqbb/5NZ6VVWVZs6cqXPPPVcul0utW7fW9OnTJUnJycmSpJ49e8owDA0YMMBz3MKFC9WpUydFRkaqY8eOmjt3brXrbNiwQT179lRkZKR69eqlTZs2ef07mjVrlrp166bGjRsrKSlJY8eOVWFh4SmfW7Fihc477zxFRkbqyiuvVF5eXrX9b775plJSUhQZGal27drp4YcfVkVFhdfxAPAeiRyOERUVpfLycs/6rl27tGzZMr322mue1vY111yj/Px8vfXWW8rJydEFF1ygyy+/XIcPH5YkLVu2TFOnTtX06dOVnZ2thISEUxLsyR588EHNnDlTkydP1rZt27RkyRLFx8dLOp6MJenf//63Dhw4oNdff12StGDBAk2aNEnTp0/X9u3bNWPGDE2ePFmLFy+WJBUVFenaa69Vhw4dlJOTo2nTpun+++/3+ncSFhamZ555Rl9//bUWL16sDz74QBMmTKj2meLiYk2fPl2LFy/WJ598ooKCAg0dOtSz/91339VNN92kcePGadu2bZo3b54WLVrk+bICwM9MIASNGDHCTEtL86x//vnnZvPmzc0bbrjBNE3TnDp1qtmwYUPz4MGDns+8//77ptvtNktKSqqd65xzzjHnzZtnmqZp9uvXzxwzZky1/X369DG7d+9e47ULCgpMl8tlLliwoMY4c3NzTUnmpk2bqm1PSkoylyxZUm3bo48+avbr1880TdOcN2+eGRsbaxYVFXn2Z2Vl1Xiu32rTpo351FNPnXb/smXLzObNm3vWFy5caEoy169f79m2fft2U5L5+eefm6Zpmpdccok5Y8aMaud58cUXzYSEBM+6JHP58uWnvS6AumOMHCFr1apVatKkiSoqKlReXq60tDTNnj3bs79NmzZq2bKlZz0nJ0eFhYVq3rx5tfMcO3ZM3333nSRp+/btGjNmTLX9/fr105o1a2qMYfv27SotLdXll19e67gPHTqkvLw8jRo1Srfffrtne0VFhWf8ffv27erevbsaNWpULQ5vrVmzRjNmzNC2bdtUUFCgiooKlZSUqKioSI0bN5YkNWjQQL169fIc07FjRzVt2lTbt2/XhRdeqJycHH3xxRfVKvDKykqVlJSouLi4WowArEciR8gaOHCgsrKy1LBhQyUmJp4yme1EojqhqqpKCQkJWrt27SnnqustWFFRUV4fU1VVJel4e71Pnz7V9oWHh0uSTNOsUzy/tWfPHl199dUaM2aMHn30UcXGxurjjz/WqFGjqg1BSMdvHzvZiW1VVVV6+OGHdd11153ymcjISJ/jBHBmJHKErMaNG+vcc8+t9ecvuOAC5efnq0GDBmrbtm2Nn+nUqZPWr1+vW265xbNt/fr1pz1n+/btFRUVpffff1+jR48+ZX9ERISk4xXsCfHx8TrrrLP0/fffa/jw4TWet3PnznrxxRd17Ngxz5eFM8VRk+zsbFVUVOgf//iHwsKOT5dZtmzZKZ+rqKhQdna2LrzwQknSjh079PPPP6tjx46Sjv/eduzY4dXvGoB1SOTAr6644gr169dPQ4YM0cyZM9WhQwft379fb731loYMGaJevXrp3nvv1YgRI9SrVy9dfPHFeumll7R161a1a9euxnNGRkZq4sSJmjBhgiIiInTRRRfp0KFD2rp1q0aNGqW4uDhFRUXpnXfe0dlnn63IyEjFxMRo2rRpGjdunNxut1JTU1VaWqrs7GwdOXJE6enpGjZsmCZNmqRRo0bpoYce0u7du/X3v//dq5/3nHPOUUVFhWbPnq3Bgwfrk08+0XPPPXfK5xo2bKh77rlHzzzzjBo2bKi7775bffv29ST2KVOm6Nprr1VSUpKuv/56hYWF6csvv9RXX32lxx57zPv/IwB4hVnrwK8Mw9Bbb72lSy+9VLfddpvOO+88DR06VLt37/bMMr/xxhs1ZcoUTZw4USkpKdqzZ4/uvPPOM5538uTJuu+++zRlyhR16tRJN954ow4ePCjp+PjzM888o3nz5ikxMVFpaWmSpNGjR+v555/XokWL1K1bN1122WVatGiR53a1Jk2a6M0339S2bdvUs2dPTZo0STNnzvTq5+3Ro4dmzZqlmTNnqmvXrnrppZeUkZFxyucaNWqkiRMnatiwYerXr5+ioqL0yiuvePZfddVVWrVqlVavXq3evXurb9++mjVrltq0aeNVPADqxjCtGGwDAAABQUUOAICNkcgBALAxEjkAADZGIgcAwMZI5AAA2BiJHAAAGyORAwBgYyRyAABsjEQOAICNkcgBALAxEjkAADb2/wDgyQUAXT3VWQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2afc630-a12b-4919-be5f-54e759d87b74",
   "metadata": {},
   "source": [
    "# Building neural network model using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3679a-4eed-474d-b55a-6b1a43b3e8e1",
   "metadata": {},
   "source": [
    "# Wide network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dde3107-4006-488e-a421-0202ffe86a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model_wide = keras.models.Sequential()\n",
    "model_wide.add(keras.layers.Input(6))\n",
    "model_wide.add(keras.layers.Dense(200, activation=\"relu\"))\n",
    "model_wide.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "072cc7cd-5715-433b-a73a-e9ae10d24eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wide.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4690fa3-6e46-4143-a937-6fb0c8a8cec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 175ms/step - loss: 1.5651 - accuracy: 0.4286 - val_loss: 1.0991 - val_accuracy: 0.5926\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.3520 - accuracy: 0.6190 - val_loss: 1.9093 - val_accuracy: 0.4815\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.3292 - accuracy: 0.6349 - val_loss: 1.4597 - val_accuracy: 0.4074\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0528 - accuracy: 0.6190 - val_loss: 0.6891 - val_accuracy: 0.5926\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6231 - accuracy: 0.6349 - val_loss: 0.6694 - val_accuracy: 0.5556\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.7411 - accuracy: 0.5238 - val_loss: 0.6781 - val_accuracy: 0.6296\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7172 - accuracy: 0.5556 - val_loss: 0.6577 - val_accuracy: 0.6667\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6509 - accuracy: 0.6190 - val_loss: 0.7512 - val_accuracy: 0.5185\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6340 - accuracy: 0.6984 - val_loss: 0.8660 - val_accuracy: 0.4815\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6359 - accuracy: 0.7143 - val_loss: 0.7815 - val_accuracy: 0.4444\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5715 - accuracy: 0.6667 - val_loss: 0.6776 - val_accuracy: 0.5185\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5526 - accuracy: 0.6825 - val_loss: 0.6459 - val_accuracy: 0.5926\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5575 - accuracy: 0.6508 - val_loss: 0.6427 - val_accuracy: 0.5556\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5499 - accuracy: 0.6825 - val_loss: 0.6599 - val_accuracy: 0.5556\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5281 - accuracy: 0.7778 - val_loss: 0.7131 - val_accuracy: 0.4815\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5269 - accuracy: 0.7619 - val_loss: 0.7309 - val_accuracy: 0.4815\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5252 - accuracy: 0.7460 - val_loss: 0.6855 - val_accuracy: 0.5556\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5139 - accuracy: 0.7460 - val_loss: 0.6307 - val_accuracy: 0.6667\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5028 - accuracy: 0.7460 - val_loss: 0.6159 - val_accuracy: 0.6667\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4975 - accuracy: 0.7778 - val_loss: 0.6316 - val_accuracy: 0.6296\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4838 - accuracy: 0.7619 - val_loss: 0.6587 - val_accuracy: 0.5556\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4850 - accuracy: 0.7619 - val_loss: 0.6675 - val_accuracy: 0.5556\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4790 - accuracy: 0.7302 - val_loss: 0.6210 - val_accuracy: 0.7037\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4710 - accuracy: 0.7619 - val_loss: 0.5898 - val_accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4659 - accuracy: 0.7778 - val_loss: 0.5855 - val_accuracy: 0.7037\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4614 - accuracy: 0.7778 - val_loss: 0.5935 - val_accuracy: 0.7037\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4584 - accuracy: 0.7778 - val_loss: 0.5867 - val_accuracy: 0.7037\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4533 - accuracy: 0.7778 - val_loss: 0.5878 - val_accuracy: 0.7037\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.5775 - val_accuracy: 0.7037\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4486 - accuracy: 0.7778 - val_loss: 0.5624 - val_accuracy: 0.7778\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4458 - accuracy: 0.7778 - val_loss: 0.5669 - val_accuracy: 0.7407\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4423 - accuracy: 0.7778 - val_loss: 0.5860 - val_accuracy: 0.7037\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4387 - accuracy: 0.7937 - val_loss: 0.5929 - val_accuracy: 0.7037\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4382 - accuracy: 0.7937 - val_loss: 0.5763 - val_accuracy: 0.7037\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4322 - accuracy: 0.7778 - val_loss: 0.5722 - val_accuracy: 0.7037\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4299 - accuracy: 0.7778 - val_loss: 0.5723 - val_accuracy: 0.7037\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4259 - accuracy: 0.7937 - val_loss: 0.5850 - val_accuracy: 0.7037\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4241 - accuracy: 0.7937 - val_loss: 0.5842 - val_accuracy: 0.7037\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4242 - accuracy: 0.7937 - val_loss: 0.5618 - val_accuracy: 0.7407\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4195 - accuracy: 0.7937 - val_loss: 0.5629 - val_accuracy: 0.7407\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4157 - accuracy: 0.7937 - val_loss: 0.5612 - val_accuracy: 0.7407\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4132 - accuracy: 0.7937 - val_loss: 0.5591 - val_accuracy: 0.7407\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4133 - accuracy: 0.8095 - val_loss: 0.5631 - val_accuracy: 0.7407\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4111 - accuracy: 0.7937 - val_loss: 0.5419 - val_accuracy: 0.7778\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4068 - accuracy: 0.7937 - val_loss: 0.5486 - val_accuracy: 0.7407\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4059 - accuracy: 0.8095 - val_loss: 0.5558 - val_accuracy: 0.7407\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4002 - accuracy: 0.8095 - val_loss: 0.5452 - val_accuracy: 0.7407\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3984 - accuracy: 0.7937 - val_loss: 0.5353 - val_accuracy: 0.7778\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3965 - accuracy: 0.7937 - val_loss: 0.5362 - val_accuracy: 0.7407\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3925 - accuracy: 0.8095 - val_loss: 0.5482 - val_accuracy: 0.7407\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3915 - accuracy: 0.8095 - val_loss: 0.5588 - val_accuracy: 0.7407\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3916 - accuracy: 0.8095 - val_loss: 0.5491 - val_accuracy: 0.7407\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3858 - accuracy: 0.8095 - val_loss: 0.5224 - val_accuracy: 0.7778\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3862 - accuracy: 0.8095 - val_loss: 0.5158 - val_accuracy: 0.7778\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3834 - accuracy: 0.8095 - val_loss: 0.5253 - val_accuracy: 0.7407\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3804 - accuracy: 0.8095 - val_loss: 0.5467 - val_accuracy: 0.7407\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3781 - accuracy: 0.8095 - val_loss: 0.5433 - val_accuracy: 0.7407\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3800 - accuracy: 0.8095 - val_loss: 0.5168 - val_accuracy: 0.7778\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3749 - accuracy: 0.8254 - val_loss: 0.5133 - val_accuracy: 0.7778\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3710 - accuracy: 0.8254 - val_loss: 0.5295 - val_accuracy: 0.7407\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3692 - accuracy: 0.8095 - val_loss: 0.5394 - val_accuracy: 0.7407\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3676 - accuracy: 0.8095 - val_loss: 0.5272 - val_accuracy: 0.7407\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3648 - accuracy: 0.8254 - val_loss: 0.5149 - val_accuracy: 0.7407\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3650 - accuracy: 0.8254 - val_loss: 0.5065 - val_accuracy: 0.7778\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3630 - accuracy: 0.8254 - val_loss: 0.5120 - val_accuracy: 0.7407\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3584 - accuracy: 0.8413 - val_loss: 0.5279 - val_accuracy: 0.7407\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3590 - accuracy: 0.8413 - val_loss: 0.5273 - val_accuracy: 0.7407\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3558 - accuracy: 0.8413 - val_loss: 0.5211 - val_accuracy: 0.7407\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3540 - accuracy: 0.8413 - val_loss: 0.5107 - val_accuracy: 0.7407\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3508 - accuracy: 0.8413 - val_loss: 0.5030 - val_accuracy: 0.7778\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3532 - accuracy: 0.8254 - val_loss: 0.4923 - val_accuracy: 0.7778\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3485 - accuracy: 0.8254 - val_loss: 0.5036 - val_accuracy: 0.7778\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3454 - accuracy: 0.8413 - val_loss: 0.5200 - val_accuracy: 0.7407\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3497 - accuracy: 0.8413 - val_loss: 0.5232 - val_accuracy: 0.7037\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3447 - accuracy: 0.8413 - val_loss: 0.4871 - val_accuracy: 0.7778\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3439 - accuracy: 0.8413 - val_loss: 0.4793 - val_accuracy: 0.7778\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3419 - accuracy: 0.8571 - val_loss: 0.4913 - val_accuracy: 0.7778\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3387 - accuracy: 0.8413 - val_loss: 0.5258 - val_accuracy: 0.7037\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3390 - accuracy: 0.8730 - val_loss: 0.5317 - val_accuracy: 0.7037\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3360 - accuracy: 0.8730 - val_loss: 0.4969 - val_accuracy: 0.7407\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3309 - accuracy: 0.8413 - val_loss: 0.4794 - val_accuracy: 0.7778\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3321 - accuracy: 0.8571 - val_loss: 0.4747 - val_accuracy: 0.8148\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3305 - accuracy: 0.8571 - val_loss: 0.4823 - val_accuracy: 0.7778\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3274 - accuracy: 0.8413 - val_loss: 0.5091 - val_accuracy: 0.7407\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3291 - accuracy: 0.8889 - val_loss: 0.5087 - val_accuracy: 0.7407\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3260 - accuracy: 0.8730 - val_loss: 0.4730 - val_accuracy: 0.8519\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3246 - accuracy: 0.8730 - val_loss: 0.4646 - val_accuracy: 0.8519\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3235 - accuracy: 0.8730 - val_loss: 0.4742 - val_accuracy: 0.8519\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3196 - accuracy: 0.8730 - val_loss: 0.5076 - val_accuracy: 0.7407\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3200 - accuracy: 0.8889 - val_loss: 0.5185 - val_accuracy: 0.7037\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3223 - accuracy: 0.8889 - val_loss: 0.4809 - val_accuracy: 0.8148\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3132 - accuracy: 0.8889 - val_loss: 0.4763 - val_accuracy: 0.8148\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3118 - accuracy: 0.9048 - val_loss: 0.4741 - val_accuracy: 0.8148\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3105 - accuracy: 0.9048 - val_loss: 0.4763 - val_accuracy: 0.8148\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3090 - accuracy: 0.8889 - val_loss: 0.4814 - val_accuracy: 0.8148\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3071 - accuracy: 0.8889 - val_loss: 0.4906 - val_accuracy: 0.7407\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3070 - accuracy: 0.8889 - val_loss: 0.4829 - val_accuracy: 0.7778\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3045 - accuracy: 0.8889 - val_loss: 0.4625 - val_accuracy: 0.8519\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3092 - accuracy: 0.8889 - val_loss: 0.4516 - val_accuracy: 0.8519\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3027 - accuracy: 0.8730 - val_loss: 0.4674 - val_accuracy: 0.8519\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3014 - accuracy: 0.8889 - val_loss: 0.5010 - val_accuracy: 0.7037\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3024 - accuracy: 0.8889 - val_loss: 0.4913 - val_accuracy: 0.7407\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2975 - accuracy: 0.8889 - val_loss: 0.4622 - val_accuracy: 0.8519\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2976 - accuracy: 0.9048 - val_loss: 0.4574 - val_accuracy: 0.8519\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2962 - accuracy: 0.9048 - val_loss: 0.4532 - val_accuracy: 0.8519\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2934 - accuracy: 0.9048 - val_loss: 0.4657 - val_accuracy: 0.8148\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2940 - accuracy: 0.9048 - val_loss: 0.4936 - val_accuracy: 0.7407\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2981 - accuracy: 0.8889 - val_loss: 0.4943 - val_accuracy: 0.7037\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2891 - accuracy: 0.8889 - val_loss: 0.4604 - val_accuracy: 0.8519\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2890 - accuracy: 0.8889 - val_loss: 0.4347 - val_accuracy: 0.8519\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2914 - accuracy: 0.8730 - val_loss: 0.4405 - val_accuracy: 0.8519\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2873 - accuracy: 0.9048 - val_loss: 0.4640 - val_accuracy: 0.8148\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2823 - accuracy: 0.9048 - val_loss: 0.4721 - val_accuracy: 0.8148\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2862 - accuracy: 0.8889 - val_loss: 0.4604 - val_accuracy: 0.8148\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2803 - accuracy: 0.9048 - val_loss: 0.4667 - val_accuracy: 0.8148\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2790 - accuracy: 0.8889 - val_loss: 0.4578 - val_accuracy: 0.8148\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2821 - accuracy: 0.8889 - val_loss: 0.4641 - val_accuracy: 0.8148\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2754 - accuracy: 0.9048 - val_loss: 0.4494 - val_accuracy: 0.8519\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2757 - accuracy: 0.9048 - val_loss: 0.4360 - val_accuracy: 0.8519\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2764 - accuracy: 0.9048 - val_loss: 0.4380 - val_accuracy: 0.8519\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2821 - accuracy: 0.9048 - val_loss: 0.4714 - val_accuracy: 0.8148\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2729 - accuracy: 0.9048 - val_loss: 0.4638 - val_accuracy: 0.8519\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2780 - accuracy: 0.9048 - val_loss: 0.4312 - val_accuracy: 0.8519\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2740 - accuracy: 0.9048 - val_loss: 0.4405 - val_accuracy: 0.8519\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2682 - accuracy: 0.9206 - val_loss: 0.4467 - val_accuracy: 0.8148\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2652 - accuracy: 0.9206 - val_loss: 0.4487 - val_accuracy: 0.8148\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2677 - accuracy: 0.9048 - val_loss: 0.4587 - val_accuracy: 0.8519\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2658 - accuracy: 0.9048 - val_loss: 0.4506 - val_accuracy: 0.8148\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2618 - accuracy: 0.9048 - val_loss: 0.4309 - val_accuracy: 0.8519\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2647 - accuracy: 0.8889 - val_loss: 0.4272 - val_accuracy: 0.8519\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2635 - accuracy: 0.9206 - val_loss: 0.4509 - val_accuracy: 0.8519\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2626 - accuracy: 0.9206 - val_loss: 0.4656 - val_accuracy: 0.8519\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2581 - accuracy: 0.9048 - val_loss: 0.4427 - val_accuracy: 0.8519\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2557 - accuracy: 0.9206 - val_loss: 0.4296 - val_accuracy: 0.8519\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2554 - accuracy: 0.9206 - val_loss: 0.4323 - val_accuracy: 0.8519\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2564 - accuracy: 0.9206 - val_loss: 0.4339 - val_accuracy: 0.8519\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2587 - accuracy: 0.9206 - val_loss: 0.4635 - val_accuracy: 0.8519\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2535 - accuracy: 0.9048 - val_loss: 0.4453 - val_accuracy: 0.8519\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2494 - accuracy: 0.9206 - val_loss: 0.4373 - val_accuracy: 0.8519\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2492 - accuracy: 0.9206 - val_loss: 0.4287 - val_accuracy: 0.8519\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2529 - accuracy: 0.9206 - val_loss: 0.4440 - val_accuracy: 0.8519\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2458 - accuracy: 0.9206 - val_loss: 0.4389 - val_accuracy: 0.8519\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2449 - accuracy: 0.9206 - val_loss: 0.4369 - val_accuracy: 0.8519\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2495 - accuracy: 0.9048 - val_loss: 0.4222 - val_accuracy: 0.8519\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2428 - accuracy: 0.9206 - val_loss: 0.4347 - val_accuracy: 0.8519\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2442 - accuracy: 0.9206 - val_loss: 0.4543 - val_accuracy: 0.8519\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2422 - accuracy: 0.9206 - val_loss: 0.4453 - val_accuracy: 0.8519\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2407 - accuracy: 0.9206 - val_loss: 0.4198 - val_accuracy: 0.8519\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2428 - accuracy: 0.9365 - val_loss: 0.4134 - val_accuracy: 0.8889\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2380 - accuracy: 0.9048 - val_loss: 0.4282 - val_accuracy: 0.8519\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2339 - accuracy: 0.9206 - val_loss: 0.4518 - val_accuracy: 0.8519\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2364 - accuracy: 0.9206 - val_loss: 0.4521 - val_accuracy: 0.8519\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2378 - accuracy: 0.9206 - val_loss: 0.4536 - val_accuracy: 0.8519\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2537 - accuracy: 0.9206 - val_loss: 0.4103 - val_accuracy: 0.8889\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2347 - accuracy: 0.9206 - val_loss: 0.4171 - val_accuracy: 0.8889\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2331 - accuracy: 0.9048 - val_loss: 0.4399 - val_accuracy: 0.8519\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2291 - accuracy: 0.9365 - val_loss: 0.4465 - val_accuracy: 0.8519\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2288 - accuracy: 0.9365 - val_loss: 0.4389 - val_accuracy: 0.8519\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2274 - accuracy: 0.9365 - val_loss: 0.4266 - val_accuracy: 0.8519\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2265 - accuracy: 0.9365 - val_loss: 0.4207 - val_accuracy: 0.8519\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2259 - accuracy: 0.9206 - val_loss: 0.4218 - val_accuracy: 0.8519\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2287 - accuracy: 0.9365 - val_loss: 0.4410 - val_accuracy: 0.8519\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2254 - accuracy: 0.9365 - val_loss: 0.4387 - val_accuracy: 0.8519\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2248 - accuracy: 0.9365 - val_loss: 0.4277 - val_accuracy: 0.8519\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2218 - accuracy: 0.9206 - val_loss: 0.4096 - val_accuracy: 0.8889\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2265 - accuracy: 0.9206 - val_loss: 0.4066 - val_accuracy: 0.8889\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2209 - accuracy: 0.9365 - val_loss: 0.4267 - val_accuracy: 0.8519\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2209 - accuracy: 0.9365 - val_loss: 0.4599 - val_accuracy: 0.8519\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2222 - accuracy: 0.9365 - val_loss: 0.4472 - val_accuracy: 0.8519\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2200 - accuracy: 0.9365 - val_loss: 0.4135 - val_accuracy: 0.8889\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2213 - accuracy: 0.9365 - val_loss: 0.4035 - val_accuracy: 0.8889\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2182 - accuracy: 0.9206 - val_loss: 0.4186 - val_accuracy: 0.8519\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2258 - accuracy: 0.9365 - val_loss: 0.4525 - val_accuracy: 0.8519\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2168 - accuracy: 0.9365 - val_loss: 0.4273 - val_accuracy: 0.8519\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2132 - accuracy: 0.9365 - val_loss: 0.4121 - val_accuracy: 0.8889\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2136 - accuracy: 0.9524 - val_loss: 0.4089 - val_accuracy: 0.8889\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2121 - accuracy: 0.9365 - val_loss: 0.4169 - val_accuracy: 0.8889\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2104 - accuracy: 0.9365 - val_loss: 0.4378 - val_accuracy: 0.8519\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2106 - accuracy: 0.9365 - val_loss: 0.4372 - val_accuracy: 0.8519\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2114 - accuracy: 0.9365 - val_loss: 0.4367 - val_accuracy: 0.8519\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2067 - accuracy: 0.9365 - val_loss: 0.4154 - val_accuracy: 0.8889\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2112 - accuracy: 0.9524 - val_loss: 0.4001 - val_accuracy: 0.8889\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2106 - accuracy: 0.9365 - val_loss: 0.4047 - val_accuracy: 0.8889\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2109 - accuracy: 0.9365 - val_loss: 0.4409 - val_accuracy: 0.8519\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2097 - accuracy: 0.9365 - val_loss: 0.4287 - val_accuracy: 0.8519\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2059 - accuracy: 0.9365 - val_loss: 0.4194 - val_accuracy: 0.8519\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2017 - accuracy: 0.9365 - val_loss: 0.4221 - val_accuracy: 0.8519\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2015 - accuracy: 0.9365 - val_loss: 0.4167 - val_accuracy: 0.8889\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2018 - accuracy: 0.9365 - val_loss: 0.4243 - val_accuracy: 0.8519\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1993 - accuracy: 0.9365 - val_loss: 0.4209 - val_accuracy: 0.8889\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1999 - accuracy: 0.9365 - val_loss: 0.4196 - val_accuracy: 0.8889\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1995 - accuracy: 0.9365 - val_loss: 0.4148 - val_accuracy: 0.8889\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1975 - accuracy: 0.9365 - val_loss: 0.4104 - val_accuracy: 0.8889\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1989 - accuracy: 0.9524 - val_loss: 0.4114 - val_accuracy: 0.8889\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1950 - accuracy: 0.9524 - val_loss: 0.4088 - val_accuracy: 0.8889\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1957 - accuracy: 0.9524 - val_loss: 0.4138 - val_accuracy: 0.8889\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1933 - accuracy: 0.9524 - val_loss: 0.4157 - val_accuracy: 0.8889\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1923 - accuracy: 0.9524 - val_loss: 0.4172 - val_accuracy: 0.8889\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1924 - accuracy: 0.9524 - val_loss: 0.4124 - val_accuracy: 0.8889\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1912 - accuracy: 0.9524 - val_loss: 0.4220 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "history = model_wide.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b18ef77d-5675-4862-bf04-bd1a7d3ff24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 31ms/step - loss: 0.4220 - accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_wide.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39f2e3f2-f9f3-4551-82cf-b2cde52370b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 0.42197\n",
      "Accuracy 0.8889\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loss {loss:.5f}\\nAccuracy {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ccb50ce3-988f-4cae-9e1a-ec62465cd3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_16 (Dense)            (None, 200)               1400      \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,601\n",
      "Trainable params: 1,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_wide.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4f540ec3-8a60-419c-b6c6-7466141fe013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Result_of_Treatment', 1)]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# for reference, list the frequency of each digit found in the y_test data\n",
    "print(sorted(collections.Counter(y_test).items(), key=lambda i: i[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "08450b8e-43a5-4eeb-bd08-297621a0e83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# display the confusion matrix\n",
    "y_pred = model_wide.predict(X_test).argmax(axis=1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4b9a1cd-8759-4dce-9abc-713a3a9ebb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5556    1.0000    0.7143        15\n",
      "           1     0.0000    0.0000    0.0000        12\n",
      "\n",
      "    accuracy                         0.5556        27\n",
      "   macro avg     0.2778    0.5000    0.3571        27\n",
      "weighted avg     0.3086    0.5556    0.3968        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb0b20c-1a03-443b-998d-617f5915368a",
   "metadata": {},
   "source": [
    "# 2.2 Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef6e62d3-0314-4107-b264-275edfaa5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3baa59e5-41e5-4cb0-af1f-27eb89342093",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deep = keras.models.Sequential()\n",
    "model_deep.add(keras.layers.Input(6))\n",
    "model_deep.add(keras.layers.Dense(200, activation=\"relu\"))\n",
    "model_deep.add(keras.layers.Dense(200, activation=\"relu\"))\n",
    "model_deep.add(keras.layers.Dense(200, activation=\"relu\"))\n",
    "model_deep.add(keras.layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0e9664e8-c057-495d-9f35-044bc7a4d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other syntax\n",
    "input_ = keras.layers.Input(6)\n",
    "hidden1 = keras.layers.Dense(128, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(128, activation=\"relu\")(hidden1)\n",
    "hidden3 = keras.layers.Dense(128, activation=\"relu\")(hidden2)\n",
    "hidden4 = keras.layers.Dense(128, activation=\"relu\")(hidden3)\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\")(hidden4)\n",
    "model_deep = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "993e1c85-cab6-4a13-bcf9-b504a0658358",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_deep.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fb73afdb-2304-42a6-9007-e8ab329752b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2/2 [==============================] - 1s 201ms/step - loss: 0.8397 - accuracy: 0.6508 - val_loss: 2.6463 - val_accuracy: 0.3704\n",
      "Epoch 2/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.3640 - accuracy: 0.6508 - val_loss: 0.6975 - val_accuracy: 0.5556\n",
      "Epoch 3/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.8105 - accuracy: 0.4286 - val_loss: 0.8019 - val_accuracy: 0.5556\n",
      "Epoch 4/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8438 - accuracy: 0.4444 - val_loss: 0.6794 - val_accuracy: 0.5556\n",
      "Epoch 5/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5914 - accuracy: 0.6984 - val_loss: 1.0754 - val_accuracy: 0.4444\n",
      "Epoch 6/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7071 - accuracy: 0.6825 - val_loss: 0.8024 - val_accuracy: 0.4444\n",
      "Epoch 7/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5787 - accuracy: 0.6984 - val_loss: 0.6710 - val_accuracy: 0.5556\n",
      "Epoch 8/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5671 - accuracy: 0.6667 - val_loss: 0.6415 - val_accuracy: 0.6667\n",
      "Epoch 9/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5616 - accuracy: 0.6349 - val_loss: 0.6382 - val_accuracy: 0.5926\n",
      "Epoch 10/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5096 - accuracy: 0.7937 - val_loss: 0.7089 - val_accuracy: 0.4815\n",
      "Epoch 11/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5292 - accuracy: 0.7143 - val_loss: 0.6969 - val_accuracy: 0.5556\n",
      "Epoch 12/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4665 - accuracy: 0.7619 - val_loss: 0.5910 - val_accuracy: 0.7407\n",
      "Epoch 13/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4765 - accuracy: 0.7937 - val_loss: 0.5900 - val_accuracy: 0.7407\n",
      "Epoch 14/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4606 - accuracy: 0.8095 - val_loss: 0.6052 - val_accuracy: 0.6667\n",
      "Epoch 15/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4381 - accuracy: 0.8254 - val_loss: 0.6557 - val_accuracy: 0.6296\n",
      "Epoch 16/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4250 - accuracy: 0.8095 - val_loss: 0.6407 - val_accuracy: 0.6667\n",
      "Epoch 17/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4068 - accuracy: 0.8254 - val_loss: 0.6269 - val_accuracy: 0.6296\n",
      "Epoch 18/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.3925 - accuracy: 0.8254 - val_loss: 0.5980 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3865 - accuracy: 0.8413 - val_loss: 0.5899 - val_accuracy: 0.7407\n",
      "Epoch 20/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3697 - accuracy: 0.8571 - val_loss: 0.5755 - val_accuracy: 0.7407\n",
      "Epoch 21/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3597 - accuracy: 0.8254 - val_loss: 0.6058 - val_accuracy: 0.6667\n",
      "Epoch 22/50\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3547 - accuracy: 0.8571 - val_loss: 0.6345 - val_accuracy: 0.6296\n",
      "Epoch 23/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3428 - accuracy: 0.8730 - val_loss: 0.5637 - val_accuracy: 0.7407\n",
      "Epoch 24/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3301 - accuracy: 0.8571 - val_loss: 0.5651 - val_accuracy: 0.7407\n",
      "Epoch 25/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3399 - accuracy: 0.8889 - val_loss: 0.6084 - val_accuracy: 0.6667\n",
      "Epoch 26/50\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.3254 - accuracy: 0.8730 - val_loss: 0.5290 - val_accuracy: 0.7778\n",
      "Epoch 27/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3316 - accuracy: 0.8413 - val_loss: 0.5506 - val_accuracy: 0.7778\n",
      "Epoch 28/50\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2982 - accuracy: 0.9048 - val_loss: 0.7036 - val_accuracy: 0.7407\n",
      "Epoch 29/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3195 - accuracy: 0.8889 - val_loss: 0.5654 - val_accuracy: 0.7778\n",
      "Epoch 30/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2847 - accuracy: 0.9048 - val_loss: 0.5330 - val_accuracy: 0.8148\n",
      "Epoch 31/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2753 - accuracy: 0.8730 - val_loss: 0.5823 - val_accuracy: 0.8148\n",
      "Epoch 32/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2650 - accuracy: 0.9206 - val_loss: 0.5737 - val_accuracy: 0.8148\n",
      "Epoch 33/50\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2637 - accuracy: 0.9206 - val_loss: 0.5446 - val_accuracy: 0.8519\n",
      "Epoch 34/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2583 - accuracy: 0.9048 - val_loss: 0.5345 - val_accuracy: 0.8519\n",
      "Epoch 35/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2460 - accuracy: 0.9048 - val_loss: 0.5745 - val_accuracy: 0.8148\n",
      "Epoch 36/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2500 - accuracy: 0.8889 - val_loss: 0.5099 - val_accuracy: 0.8519\n",
      "Epoch 37/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2439 - accuracy: 0.9048 - val_loss: 0.5370 - val_accuracy: 0.8519\n",
      "Epoch 38/50\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2331 - accuracy: 0.9365 - val_loss: 0.6527 - val_accuracy: 0.7778\n",
      "Epoch 39/50\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2380 - accuracy: 0.9206 - val_loss: 0.5074 - val_accuracy: 0.8519\n",
      "Epoch 40/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2196 - accuracy: 0.8889 - val_loss: 0.5060 - val_accuracy: 0.8519\n",
      "Epoch 41/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2152 - accuracy: 0.9048 - val_loss: 0.5244 - val_accuracy: 0.8519\n",
      "Epoch 42/50\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2051 - accuracy: 0.9048 - val_loss: 0.5586 - val_accuracy: 0.8148\n",
      "Epoch 43/50\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2070 - accuracy: 0.9206 - val_loss: 0.5393 - val_accuracy: 0.8519\n",
      "Epoch 44/50\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2117 - accuracy: 0.8889 - val_loss: 0.4928 - val_accuracy: 0.9259\n",
      "Epoch 45/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1983 - accuracy: 0.9206 - val_loss: 0.5775 - val_accuracy: 0.8148\n",
      "Epoch 46/50\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1939 - accuracy: 0.9206 - val_loss: 0.5518 - val_accuracy: 0.8148\n",
      "Epoch 47/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1928 - accuracy: 0.9048 - val_loss: 0.4954 - val_accuracy: 0.9259\n",
      "Epoch 48/50\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1810 - accuracy: 0.9048 - val_loss: 0.5473 - val_accuracy: 0.8148\n",
      "Epoch 49/50\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1950 - accuracy: 0.9206 - val_loss: 0.5535 - val_accuracy: 0.8148\n",
      "Epoch 50/50\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1780 - accuracy: 0.9524 - val_loss: 0.5036 - val_accuracy: 0.9259\n"
     ]
    }
   ],
   "source": [
    "history = model_deep.fit(X_train, y_train, epochs=50, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d68c67b8-0d33-41e7-9008-0a5177b48c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5036 - accuracy: 0.9259\n",
      "Loss 0.50364\n",
      "Accuracy 0.9259\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_deep.evaluate(X_test, y_test)\n",
    "print(f\"Loss {loss:.5f}\\nAccuracy {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eca55ba3-b35b-4b01-8913-4314d0446017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 128)               896       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,561\n",
      "Trainable params: 50,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_deep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9caafffe-964a-4c71-8354-fb42b2c303ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Result_of_Treatment', 1)]\n",
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# for reference, list the frequency of each digit found in the y_test data\n",
    "print(sorted(collections.Counter(y_test).items(), key=lambda i: i[0]))\n",
    "\n",
    "# display the confusion matrix\n",
    "y_pred = model_deep.predict(X_test).argmax(axis=1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6feb9b27-570c-4472-bf9f-623cc324db73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5556    1.0000    0.7143        15\n",
      "           1     0.0000    0.0000    0.0000        12\n",
      "\n",
      "    accuracy                         0.5556        27\n",
      "   macro avg     0.2778    0.5000    0.3571        27\n",
      "weighted avg     0.3086    0.5556    0.3968        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98f29a-04c4-4b5a-a058-2663b946c73e",
   "metadata": {},
   "source": [
    "# 2.3 Wide and Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3ab227b0-493e-4db5-ae27-96d1c7ec4588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c837ce93-1a05-4c4b-9185-f81c954b3ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(6)\n",
    "hidden1 = keras.layers.Dense(128, activation=\"relu\")(input_)\n",
    "hidden2 = keras.layers.Dense(128, activation=\"relu\")(hidden1)\n",
    "hidden3 = keras.layers.Dense(128, activation=\"relu\")(hidden2)\n",
    "hidden4 = keras.layers.Dense(128, activation=\"relu\")(hidden3)\n",
    "concat = keras.layers.Concatenate()([input_, hidden3])\n",
    "output = keras.layers.Dense(1, activation=\"sigmoid\")(concat)\n",
    "model_wide_deep = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf654fcc-2d79-4c4e-9f78-366b91f3e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_wide_deep.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c2047787-07f3-497c-a22f-9d5050ada857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 67ms/step - loss: 0.2759 - accuracy: 0.9048 - val_loss: 0.5423 - val_accuracy: 0.7407\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2784 - accuracy: 0.8889 - val_loss: 0.5379 - val_accuracy: 0.7407\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2738 - accuracy: 0.8889 - val_loss: 0.6006 - val_accuracy: 0.7037\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2687 - accuracy: 0.9048 - val_loss: 0.5533 - val_accuracy: 0.7407\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2642 - accuracy: 0.9048 - val_loss: 0.5246 - val_accuracy: 0.7407\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2759 - accuracy: 0.8730 - val_loss: 0.5250 - val_accuracy: 0.7778\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2584 - accuracy: 0.9365 - val_loss: 0.6266 - val_accuracy: 0.7037\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2782 - accuracy: 0.8730 - val_loss: 0.5110 - val_accuracy: 0.8148\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.2596 - accuracy: 0.9048 - val_loss: 0.5102 - val_accuracy: 0.7778\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2595 - accuracy: 0.9048 - val_loss: 0.5723 - val_accuracy: 0.7407\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2606 - accuracy: 0.8730 - val_loss: 0.5580 - val_accuracy: 0.7778\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2425 - accuracy: 0.9048 - val_loss: 0.4892 - val_accuracy: 0.8148\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2504 - accuracy: 0.8889 - val_loss: 0.4983 - val_accuracy: 0.8148\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2410 - accuracy: 0.8889 - val_loss: 0.5488 - val_accuracy: 0.7778\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2454 - accuracy: 0.8889 - val_loss: 0.5929 - val_accuracy: 0.7778\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2368 - accuracy: 0.9365 - val_loss: 0.4996 - val_accuracy: 0.8148\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2401 - accuracy: 0.8889 - val_loss: 0.4818 - val_accuracy: 0.8148\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.2309 - accuracy: 0.8889 - val_loss: 0.5528 - val_accuracy: 0.7778\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2279 - accuracy: 0.9524 - val_loss: 0.5513 - val_accuracy: 0.7778\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2438 - accuracy: 0.8730 - val_loss: 0.5256 - val_accuracy: 0.7778\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2149 - accuracy: 0.9365 - val_loss: 0.4711 - val_accuracy: 0.8148\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2362 - accuracy: 0.8889 - val_loss: 0.4786 - val_accuracy: 0.8148\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2119 - accuracy: 0.9524 - val_loss: 0.6738 - val_accuracy: 0.7407\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2727 - accuracy: 0.8571 - val_loss: 0.4880 - val_accuracy: 0.8519\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3125 - accuracy: 0.8571 - val_loss: 0.5015 - val_accuracy: 0.8519\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2546 - accuracy: 0.9206 - val_loss: 0.7581 - val_accuracy: 0.6296\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3203 - accuracy: 0.8730 - val_loss: 0.7880 - val_accuracy: 0.6296\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2987 - accuracy: 0.8889 - val_loss: 0.5022 - val_accuracy: 0.8148\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.2618 - accuracy: 0.8730 - val_loss: 0.4904 - val_accuracy: 0.8148\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.2258 - accuracy: 0.9206 - val_loss: 0.6429 - val_accuracy: 0.7778\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.2319 - accuracy: 0.9048 - val_loss: 0.6249 - val_accuracy: 0.7407\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2215 - accuracy: 0.9048 - val_loss: 0.4890 - val_accuracy: 0.7778\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2179 - accuracy: 0.8889 - val_loss: 0.4411 - val_accuracy: 0.9259\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.2075 - accuracy: 0.9048 - val_loss: 0.4993 - val_accuracy: 0.7778\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2038 - accuracy: 0.9365 - val_loss: 0.5551 - val_accuracy: 0.7778\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2020 - accuracy: 0.9365 - val_loss: 0.4552 - val_accuracy: 0.8519\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1975 - accuracy: 0.9048 - val_loss: 0.4427 - val_accuracy: 0.8889\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1878 - accuracy: 0.9206 - val_loss: 0.5044 - val_accuracy: 0.7778\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1912 - accuracy: 0.9365 - val_loss: 0.4943 - val_accuracy: 0.7778\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1821 - accuracy: 0.9524 - val_loss: 0.4718 - val_accuracy: 0.7778\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1806 - accuracy: 0.9524 - val_loss: 0.4586 - val_accuracy: 0.8148\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1753 - accuracy: 0.9206 - val_loss: 0.4439 - val_accuracy: 0.8519\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1755 - accuracy: 0.9206 - val_loss: 0.4590 - val_accuracy: 0.8148\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1730 - accuracy: 0.9524 - val_loss: 0.4912 - val_accuracy: 0.7778\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1727 - accuracy: 0.9683 - val_loss: 0.4554 - val_accuracy: 0.7778\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1664 - accuracy: 0.9683 - val_loss: 0.4419 - val_accuracy: 0.7778\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1722 - accuracy: 0.9683 - val_loss: 0.4494 - val_accuracy: 0.7778\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1637 - accuracy: 0.9524 - val_loss: 0.4434 - val_accuracy: 0.8519\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1702 - accuracy: 0.9524 - val_loss: 0.4616 - val_accuracy: 0.7778\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1588 - accuracy: 0.9683 - val_loss: 0.4449 - val_accuracy: 0.8889\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1634 - accuracy: 0.9365 - val_loss: 0.4539 - val_accuracy: 0.8148\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.1535 - accuracy: 0.9683 - val_loss: 0.5041 - val_accuracy: 0.7778\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1639 - accuracy: 0.9365 - val_loss: 0.4511 - val_accuracy: 0.7778\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1670 - accuracy: 0.9365 - val_loss: 0.4000 - val_accuracy: 0.9259\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1750 - accuracy: 0.9365 - val_loss: 0.4558 - val_accuracy: 0.7778\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1497 - accuracy: 0.9683 - val_loss: 0.4655 - val_accuracy: 0.7778\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1456 - accuracy: 0.9683 - val_loss: 0.4385 - val_accuracy: 0.8519\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.1461 - accuracy: 0.9683 - val_loss: 0.4368 - val_accuracy: 0.8889\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1425 - accuracy: 0.9683 - val_loss: 0.4336 - val_accuracy: 0.8889\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1411 - accuracy: 0.9683 - val_loss: 0.4262 - val_accuracy: 0.8889\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1574 - accuracy: 0.9365 - val_loss: 0.4271 - val_accuracy: 0.8148\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1448 - accuracy: 0.9524 - val_loss: 0.3969 - val_accuracy: 0.9259\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1440 - accuracy: 0.9524 - val_loss: 0.4368 - val_accuracy: 0.8519\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1602 - accuracy: 0.9524 - val_loss: 0.4939 - val_accuracy: 0.8148\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1367 - accuracy: 0.9683 - val_loss: 0.4062 - val_accuracy: 0.9259\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1404 - accuracy: 0.9683 - val_loss: 0.4065 - val_accuracy: 0.9259\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1323 - accuracy: 0.9524 - val_loss: 0.4461 - val_accuracy: 0.7778\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1476 - accuracy: 0.9524 - val_loss: 0.4841 - val_accuracy: 0.7778\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1375 - accuracy: 0.9524 - val_loss: 0.3947 - val_accuracy: 0.9259\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1400 - accuracy: 0.9524 - val_loss: 0.3973 - val_accuracy: 0.9259\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1233 - accuracy: 0.9683 - val_loss: 0.4427 - val_accuracy: 0.8519\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1285 - accuracy: 0.9524 - val_loss: 0.4018 - val_accuracy: 0.8889\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1189 - accuracy: 0.9683 - val_loss: 0.4049 - val_accuracy: 0.9259\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1179 - accuracy: 0.9683 - val_loss: 0.4140 - val_accuracy: 0.9259\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1154 - accuracy: 0.9683 - val_loss: 0.4205 - val_accuracy: 0.8889\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1164 - accuracy: 0.9683 - val_loss: 0.4084 - val_accuracy: 0.9259\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1149 - accuracy: 0.9683 - val_loss: 0.4077 - val_accuracy: 0.9259\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1134 - accuracy: 0.9683 - val_loss: 0.4111 - val_accuracy: 0.8889\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1167 - accuracy: 0.9841 - val_loss: 0.4169 - val_accuracy: 0.8889\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1193 - accuracy: 0.9524 - val_loss: 0.4021 - val_accuracy: 0.9259\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1103 - accuracy: 0.9683 - val_loss: 0.4436 - val_accuracy: 0.8889\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1155 - accuracy: 0.9683 - val_loss: 0.4332 - val_accuracy: 0.8889\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1055 - accuracy: 0.9683 - val_loss: 0.4013 - val_accuracy: 0.9259\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1086 - accuracy: 0.9683 - val_loss: 0.4107 - val_accuracy: 0.9259\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1176 - accuracy: 0.9683 - val_loss: 0.4480 - val_accuracy: 0.8519\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1061 - accuracy: 0.9683 - val_loss: 0.4131 - val_accuracy: 0.9259\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1167 - accuracy: 0.9683 - val_loss: 0.4135 - val_accuracy: 0.9259\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1081 - accuracy: 0.9683 - val_loss: 0.4487 - val_accuracy: 0.8519\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1075 - accuracy: 0.9683 - val_loss: 0.4330 - val_accuracy: 0.8519\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.1024 - accuracy: 0.9683 - val_loss: 0.4009 - val_accuracy: 0.9259\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1047 - accuracy: 0.9683 - val_loss: 0.4121 - val_accuracy: 0.8519\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1071 - accuracy: 0.9683 - val_loss: 0.4569 - val_accuracy: 0.8889\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1007 - accuracy: 0.9841 - val_loss: 0.4001 - val_accuracy: 0.9259\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0979 - accuracy: 0.9841 - val_loss: 0.4092 - val_accuracy: 0.9259\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1011 - accuracy: 0.9683 - val_loss: 0.4351 - val_accuracy: 0.8519\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0933 - accuracy: 0.9841 - val_loss: 0.4131 - val_accuracy: 0.9259\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0943 - accuracy: 0.9841 - val_loss: 0.4244 - val_accuracy: 0.8889\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1011 - accuracy: 0.9524 - val_loss: 0.4187 - val_accuracy: 0.8889\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.1058 - accuracy: 0.9683 - val_loss: 0.4022 - val_accuracy: 0.9259\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0906 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.8889\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1003 - accuracy: 0.9524 - val_loss: 0.4651 - val_accuracy: 0.8889\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0974 - accuracy: 0.9683 - val_loss: 0.4012 - val_accuracy: 0.9259\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.0966 - accuracy: 0.9841 - val_loss: 0.4035 - val_accuracy: 0.9259\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1098 - accuracy: 0.9524 - val_loss: 0.4515 - val_accuracy: 0.8889\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0871 - accuracy: 0.9683 - val_loss: 0.3983 - val_accuracy: 0.9259\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1038 - accuracy: 0.9683 - val_loss: 0.3956 - val_accuracy: 0.9259\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0804 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.8889\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0960 - accuracy: 0.9524 - val_loss: 0.4263 - val_accuracy: 0.8889\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9259\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1029 - accuracy: 0.9683 - val_loss: 0.4117 - val_accuracy: 0.9259\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0911 - accuracy: 0.9524 - val_loss: 0.4971 - val_accuracy: 0.8889\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0934 - accuracy: 0.9683 - val_loss: 0.4195 - val_accuracy: 0.9259\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0775 - accuracy: 0.9841 - val_loss: 0.4164 - val_accuracy: 0.9259\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0754 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.8519\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.8519\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0740 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.8519\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0709 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.8519\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.8889\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0689 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.8889\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0686 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.8889\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0726 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.8889\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0655 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.9259\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0749 - accuracy: 0.9841 - val_loss: 0.4126 - val_accuracy: 0.8889\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0748 - accuracy: 0.9683 - val_loss: 0.4516 - val_accuracy: 0.8889\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0708 - accuracy: 0.9841 - val_loss: 0.4065 - val_accuracy: 0.8889\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0685 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9259\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0688 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.8519\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.8519\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0807 - accuracy: 0.9683 - val_loss: 0.4287 - val_accuracy: 0.9259\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0624 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.8519\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0596 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.8519\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0594 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.8889\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0613 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.8889\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0557 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.8889\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0573 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.8889\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0540 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9259\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0588 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.9259\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0531 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.9259\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0522 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.9259\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0542 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9259\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0538 - accuracy: 0.9841 - val_loss: 0.4341 - val_accuracy: 0.9259\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0548 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.8519\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0500 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9259\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0499 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.8889\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0501 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9259\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.9259\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0469 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.8889\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0478 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.8889\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0516 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.8889\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0543 - accuracy: 0.9841 - val_loss: 0.4407 - val_accuracy: 0.9259\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0486 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.8519\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0516 - accuracy: 0.9841 - val_loss: 0.4595 - val_accuracy: 0.8519\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0561 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.9259\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0512 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.8519\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.0646 - accuracy: 0.9683 - val_loss: 0.4847 - val_accuracy: 0.8519\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0635 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.9259\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0589 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.8519\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0421 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.8889\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0594 - accuracy: 0.9683 - val_loss: 0.4608 - val_accuracy: 0.8519\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9259\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0519 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.8519\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.8889\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0566 - accuracy: 0.9683 - val_loss: 0.4649 - val_accuracy: 0.8889\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0404 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9259\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0567 - accuracy: 0.9841 - val_loss: 0.4579 - val_accuracy: 0.9259\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0533 - accuracy: 0.9841 - val_loss: 0.4963 - val_accuracy: 0.8889\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0591 - accuracy: 0.9683 - val_loss: 0.4402 - val_accuracy: 0.9259\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.8889\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0944 - accuracy: 0.9683 - val_loss: 0.4374 - val_accuracy: 0.9259\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0509 - accuracy: 0.9683 - val_loss: 0.5851 - val_accuracy: 0.8519\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0723 - accuracy: 0.9683 - val_loss: 0.4457 - val_accuracy: 0.9259\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.9259\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0716 - accuracy: 0.9841 - val_loss: 0.4598 - val_accuracy: 0.8889\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0638 - accuracy: 0.9683 - val_loss: 0.5481 - val_accuracy: 0.8889\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0537 - accuracy: 0.9841 - val_loss: 0.4652 - val_accuracy: 0.9259\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0457 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.9259\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0525 - accuracy: 0.9841 - val_loss: 0.4766 - val_accuracy: 0.8519\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0375 - accuracy: 0.9841 - val_loss: 0.5237 - val_accuracy: 0.8889\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0507 - accuracy: 0.9841 - val_loss: 0.4735 - val_accuracy: 0.8889\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.9259\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0535 - accuracy: 0.9841 - val_loss: 0.4899 - val_accuracy: 0.8889\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 0.5253 - val_accuracy: 0.8519\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0400 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.8519\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0287 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.8889\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0429 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.8889\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.5148 - val_accuracy: 0.8519\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0458 - accuracy: 0.9841 - val_loss: 0.4936 - val_accuracy: 0.8519\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.9259\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0506 - accuracy: 0.9841 - val_loss: 0.4855 - val_accuracy: 0.8889\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.0351 - accuracy: 1.0000 - val_loss: 0.5523 - val_accuracy: 0.8889\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0726 - accuracy: 0.9524 - val_loss: 0.4809 - val_accuracy: 0.8519\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.0278 - accuracy: 1.0000 - val_loss: 0.5682 - val_accuracy: 0.8889\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0976 - accuracy: 0.9683 - val_loss: 0.4922 - val_accuracy: 0.8889\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0474 - accuracy: 0.9841 - val_loss: 0.5514 - val_accuracy: 0.8519\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0420 - accuracy: 1.0000 - val_loss: 0.5296 - val_accuracy: 0.8889\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0520 - accuracy: 0.9841 - val_loss: 0.5374 - val_accuracy: 0.8889\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0304 - accuracy: 1.0000 - val_loss: 0.5456 - val_accuracy: 0.8519\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0404 - accuracy: 0.9683 - val_loss: 0.5526 - val_accuracy: 0.8519\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.0289 - accuracy: 1.0000 - val_loss: 0.5173 - val_accuracy: 0.8889\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0316 - accuracy: 1.0000 - val_loss: 0.5206 - val_accuracy: 0.8889\n"
     ]
    }
   ],
   "source": [
    "history = model_wide_deep.fit(X_train, y_train, epochs=200, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c1a0afc0-8b43-4ea0-93c1-f5b0192a6a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5206 - accuracy: 0.8889\n",
      "Loss 0.52062\n",
      "Accuracy 0.8889\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_wide_deep.evaluate(X_test, y_test)\n",
    "print(f\"Loss {loss:.5f}\\nAccuracy {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "be1544af-e708-4a5d-94be-54830d766282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_8 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 128)          896         ['input_8[0][0]']                \n",
      "                                                                                                  \n",
      " dense_28 (Dense)               (None, 128)          16512       ['dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " dense_29 (Dense)               (None, 128)          16512       ['dense_28[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 134)          0           ['input_8[0][0]',                \n",
      "                                                                  'dense_29[0][0]']               \n",
      "                                                                                                  \n",
      " dense_31 (Dense)               (None, 1)            135         ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 34,055\n",
      "Trainable params: 34,055\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_wide_deep.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9a5987d8-0ef1-48a4-b472-83d4c3b65269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000174800FCA60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 84ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# display the confusion matrix\n",
    "y_pred = model_wide_deep.predict(X_test).argmax(axis=1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c0bd721c-d9e4-40d6-9829-aceed04fa188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5556    1.0000    0.7143        15\n",
      "           1     0.0000    0.0000    0.0000        12\n",
      "\n",
      "    accuracy                         0.5556        27\n",
      "   macro avg     0.2778    0.5000    0.3571        27\n",
      "weighted avg     0.3086    0.5556    0.3968        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51332264-41f5-4393-970d-88f252b66e7f",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning for keras model using sklearn random grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0bbedb3e-db08-4ac1-94cf-fdedb4e85b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def build_clf(meta, hidden_layer_sizes, dropout):\n",
    "    n_features_in_ = meta[\"n_features_in_\"]\n",
    "    n_classes_ = meta[\"n_classes_\"]\n",
    "    target_encoder_ = meta[\"target_encoder_\"]\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(shape=n_features_in_)),\n",
    "    #for hidden_layer_size in hidden_layer_sizes:\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, \n",
    "            kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "            bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), \n",
    "            activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    #though you could return a compiled model, it's not necessary, and would result in the loss of these\n",
    "    # parameters in the tune process - as they would be 'hard coded'\n",
    "    # model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy']) \n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1e14aee1-89ff-4929-8a5d-c4d8e2b96770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 32.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 6,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=6,\n",
    "    dropout=0.5,\n",
    "    optimizer=keras.optimizers.Adam,\n",
    "    optimizer__learning_rate=0.0001\n",
    ")\n",
    "keras_clf.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1e07fbe0-0967-4bbf-8db9-9e4561b29036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model': <function __main__.build_clf(meta, hidden_layer_sizes, dropout)>,\n",
       " 'build_fn': None,\n",
       " 'warm_start': False,\n",
       " 'random_state': None,\n",
       " 'optimizer': keras.optimizers.optimizer_v2.adam.Adam,\n",
       " 'loss': None,\n",
       " 'metrics': None,\n",
       " 'batch_size': None,\n",
       " 'validation_batch_size': None,\n",
       " 'verbose': 1,\n",
       " 'callbacks': None,\n",
       " 'validation_split': 0.0,\n",
       " 'shuffle': True,\n",
       " 'run_eagerly': False,\n",
       " 'epochs': 1,\n",
       " 'hidden_layer_sizes': 6,\n",
       " 'dropout': 0.5,\n",
       " 'optimizer__learning_rate': 0.0001,\n",
       " 'class_weight': None}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params = {\n",
    "    \n",
    "    # the following are model parameters, and therefore must be defined as parameters in the KarasClassifier, and then in the build_clf function\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    'model__dropout': [0, 0.1], # this will require KarasClassifier and build_clf to have hidden_layer_sizes parameter set\n",
    "    \n",
    "    # the following are 'fit' parameters, the scikeras wrapper provides these parameters. These are passed to the 'model.fit' method for each fit of the model\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10],\n",
    "    'optimizer':['adam','sgd'],\n",
    "    'loss':['binary_crossentropy'],\n",
    "    \n",
    "    # this is added to the optimizer \n",
    "    'optimizer__learning_rate': [0.0001, 0.001, 0.01]\n",
    "\n",
    "}\n",
    "keras_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f3466-5d7d-4d60-9389-07e9768af91b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 289ms/step - loss: 13.9810\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.7195\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.4592\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.1998\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.9413\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.6840\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.4281\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.1732\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.9193\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 11.6665\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 6.5187\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1994\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8807\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5625\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.2454\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9288\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6129\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2989\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9858\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6743\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 7.8259\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5443\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2634\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9832\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7037\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4248\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1465\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8689\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.5920\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.3157\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 18.5637\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 18.3080\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.0536\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.8005\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 17.5488\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.2988\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 17.0497\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.8020\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.5554\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 16.3100\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 7.4500\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2197\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9917\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7664\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.5436\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.3235\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.1059\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8907\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6775\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4663\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 11.4061\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.6331\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 9.1245\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.0409\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.9528\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.5180\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8947\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.7832\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0883\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3137\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.2573\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.4019\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.0777\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.6351\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.2678\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.5920\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.9812\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.3756\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.7651\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8677\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.6761\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.7132\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4838\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1874\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.4202\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1486\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.4501\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.7557\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7817\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.6311\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.4089\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.8487\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.9783\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1414\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0939\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8763\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0892\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8181\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7512\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8789\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 8.3383\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.1660\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.3422\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1768\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0443\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8268\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9802\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.7794\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5970\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6337\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 6.4922\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3062\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.1200\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.9358\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7545\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.5763\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4021\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2312\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0639\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9009\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 8.1247\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9095\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.6943\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4791\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2638\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0498\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8353\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6208\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4061\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.1913\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 428ms/step - loss: 4.0159\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8667\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7184\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5713\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4250\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2794\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1348\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9911\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8483\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7066\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 0.7378\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6684\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6512\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6544\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6503\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6397\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6267\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6149\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6070\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6043\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 4.0832\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9464\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8099\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6738\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5382\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4039\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2706\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1388\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0083\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8793\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 9.1569\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 24.1971\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6905\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6905\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.1999\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9656\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7728\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9162\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6826\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2572\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 350ms/step - loss: 3.2096\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 27.5221\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0732\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.5537\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9236\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.7202\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8309\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7945\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1014\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5752\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 5.5949\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.9702\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.4342\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.0856\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6197\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4599\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1341\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0021\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5175\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3194\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 305ms/step - loss: 6.6118\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 25.4995\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 14.1770\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6528\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.3448\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0314\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3744\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1515\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6793\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7392\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 3.1565\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 20.6165\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6938\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 19.7382\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0012\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.0290\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.1863\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1913\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1245\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7123\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 3.6942\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7153\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2677\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7924\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5998\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7815\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9848\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2800\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8874\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0967\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 2.3902\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7652\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6372\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5144\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0618\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4731\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0524\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4798\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3736\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7794\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 3.4865\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0382\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6813\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0626\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6432\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6824\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7712\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6482\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2380\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4448\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 1.8139\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3561\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9836\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6708\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9726\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8005\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8013\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5270\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5722\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7747\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 396ms/step - loss: 1.9823\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8683\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9936\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2902\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0393\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5985\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5309\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6243\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0025\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9439\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 335ms/step - loss: 4.9134\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9840\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9004\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9266\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1926\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8541\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6820\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3978\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7293\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8802\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 375ms/step - loss: 3.5619\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3488\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9619\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8391\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9746\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4862\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.9642\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2913\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6816\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6003\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 357ms/step - loss: 4.7821\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8695\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9660\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2516\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4267\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2050\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2302\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5590\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6990\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2477\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 254ms/step - loss: 7.5458\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1549\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6225\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6067\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7206\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7910\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.0065\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1312\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8237\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4263\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 7.6470\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7407\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0152\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5501\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0825\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1330\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5024\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5529\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2952\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7493\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 7.4474\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9888\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4503\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5301\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8111\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3756\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1104\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8912\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9824\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8976\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 402ms/step - loss: 14.5854\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.3843\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6842\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5279\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0553\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4321\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9968\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7919\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9784\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9919\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 3.6826\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9571\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0705\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9084\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6862\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6437\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7936\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4044\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2466\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7062\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 413ms/step - loss: 3.0604\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3285\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3448\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1415\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1321\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9138\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9863\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9058\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5237\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9118\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 398ms/step - loss: 12.5512\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.7091\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6827\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2223\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9321\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3827\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3951\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8202\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.6406\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8933\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.8282\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.2110\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.6422\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.9878\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2590\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9881\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.1151\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6882\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6284\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6112\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 10.0518\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9930\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2739\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.9175\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.8159\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 6.2210\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2720\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.6307\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2361\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8993\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.5186\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.2554\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.3702\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8614\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.8867\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9258\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.0089\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.8366\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7695\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6819\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.4177\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.3440\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9699\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.6918\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1802\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.4369\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.9340\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.0204\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.5691\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9033\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.7024\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.9429\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.5840\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.3766\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.0828\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.0390\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0474\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9963\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0627\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.8697\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 380ms/step - loss: 11.5153\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.9297\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.8421\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.6479\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3174\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.1488\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.8588\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.4842\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 13.1975\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 12.9905\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 367ms/step - loss: 1.9495\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6510\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7069\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2638\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3239\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3732\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.9221\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5353\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0987\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6431\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 365ms/step - loss: 6.6098\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0013\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.2940\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.4929\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8598\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7102\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0244\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.7028\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8860\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1223\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 390ms/step - loss: 3.5045\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2974\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9361\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6429\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0322\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1017\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6018\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1259\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3784\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4967\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 389ms/step - loss: 7.9034\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.1442\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5277\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.9106\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.9994\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6265\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.0915\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8388\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0102\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5484\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 5.2723\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.6107\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.1265\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.4057\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.5226\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.9330\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1814\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2258\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.2996\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8351\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.3596\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.0007\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2800\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.2867\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1449\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6943\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9879\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.7103\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8757\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8252\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 2.9858\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.2769\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.8907\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.3152\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6160\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1627\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2531\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.3861\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0896\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5930\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.5983\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8524\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.1918\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.2693\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.1971\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8046\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8614\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6295\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6861\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5180\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.4595\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.5029\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.5400\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.0242\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.7550\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9687\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6947\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6721\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5680\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5645\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 439ms/step - loss: 2.0364\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6057\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2395\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9779\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8668\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8828\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9871\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0304\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9369\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8103\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 368ms/step - loss: 4.4627\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9247\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.3907\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8630\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3482\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8624\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4457\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2739\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2913\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3981\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 13.2571\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.6960\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.1359\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5774\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.0196\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.4636\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.9103\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.3595\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8121\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.2692\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 387ms/step - loss: 3.1423\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4021\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6895\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1148\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9407\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9261\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0031\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0941\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1543\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1693\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 425ms/step - loss: 9.9415\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2093\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4800\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7535\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.0327\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3183\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.6147\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9251\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2461\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5822\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 21.0686\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.2433\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.7239\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.2884\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.8515\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.7380\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6038\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5835\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.5405\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.5857\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 11.1198\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 15.0387\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.7004\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9328\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.6358\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.6734\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6750\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6161\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6386\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.9380\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 21.4519\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.8267\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.6186\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.0123\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.0859\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.9920\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9009\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.8856\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6761\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6434\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 27.8622\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.4769\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.0750\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 0.8102\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6490\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6203\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6481\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6367\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6124\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 0.6234\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 47.3091\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.4339\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.7010\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1000us/step - loss: 5.1558\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.9822\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6961\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6563\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.6874\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.7671\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 0.6369\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 329ms/step - loss: 5.7665\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 25.8306\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0993\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.2684\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.4416\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.9694\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.5617\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.0917\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3760\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7077\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 8.6936\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 30.8294\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6513\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 17.9402\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6986\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.3583\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3328\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7028\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8897\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7006\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 12.8358\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.6045\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.8404\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7246\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.1162\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8392\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5990\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7474\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9495\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 8.6856\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5756\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.0338\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1648\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9109\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.4316\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7186\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8216\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0887\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6835\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 333ms/step - loss: 9.0962\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 34.8395\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8673\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 19.8321\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2423\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7142\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3249\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4776\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.2004\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8444\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 366ms/step - loss: 1.4049\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8290\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6737\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6861\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7552\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7972\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7892\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7413\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6748\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6134\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 369ms/step - loss: 5.6809\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.0653\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.4697\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.9032\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3700\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8674\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3887\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9370\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5402\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2703\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 384ms/step - loss: 3.2796\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7985\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3510\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9541\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6277\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3813\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2177\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1334\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.1123\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1318\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 437ms/step - loss: 9.8884\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.0985\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3479\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.6458\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9923\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.3726\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7713\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1867\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6271\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1023\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 414ms/step - loss: 19.2955\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 18.4334\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 17.5757\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.7216\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 15.8708\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 15.0225\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 14.1784\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.3379\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 12.5031\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.6783\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 467ms/step - loss: 5.1635\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.4702\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7754\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7785\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7638\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6220\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7189\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4384\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3953\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3524\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 487ms/step - loss: 2.7385\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 16.1575\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3719\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1619\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.2270\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6380\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6041\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6492\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4624\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6268\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 2.2158\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4793\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1314\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9470\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2462\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2919\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7894\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2662\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5528\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2365\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 454ms/step - loss: 3.5036\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 25.3625\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.4965\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3009\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.8350\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1037\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8220\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0643\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2639\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8797\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 471ms/step - loss: 1.4333\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.1720\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.4654\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4169\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4927\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 2.7564\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8952\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3606\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1052\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0579\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 347ms/step - loss: 8.0596\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.2230\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0583\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0924\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8688\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7003\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6935\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6882\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6838\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6801\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 315ms/step - loss: 1.7215\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2010\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3660\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3716\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3277\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3625\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3301\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.3378\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3362\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3128\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 301ms/step - loss: 1.4953\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8806\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7830\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7169\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6765\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6632\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8099\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9050\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 1.1374\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9019\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 2.4761\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6038\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4433\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4805\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4531\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3295\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4280\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2214\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4267\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1000\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 354ms/step - loss: 11.4511\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.4755\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8524\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8635\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0839\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9672\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8749\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9420\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7908\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9425\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 4.7731\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5992\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2502\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7291\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2993\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8623\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5619\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1951\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5511\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8222\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 7.4253\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.8526\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.2471\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9183\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3685\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.3313\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.6759\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6985\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.4853\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.9564\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 451ms/step - loss: 8.1515\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3376\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.7757\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2699\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8403\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.3093\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8052\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6985\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.2521\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6316\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 477ms/step - loss: 6.0960\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.9541\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6354\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6237\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2190\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9390\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.6095\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9445\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6265\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1718\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 400ms/step - loss: 9.3356\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.9251\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2260\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.7925\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.1624\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.0316\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.6159\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5911\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4760\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.8005\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 9.4959\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3541\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.1115\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6145\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.7343\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.1151\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8513\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.7174\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.9653\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.9114\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 351ms/step - loss: 4.0348\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7789\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7740\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1791\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0347\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9971\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1028\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9676\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3567\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2567\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 1.1659\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0787\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1365\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3340\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2510\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4236\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9851\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0954\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8446\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5102\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 5.4854\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.8368\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.8920\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5561\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.9696\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7924\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2523\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7645\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8731\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6191\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 4.5079\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7168\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8360\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1193\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.7898\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7409\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.2061\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7840\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5921\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6592\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 326ms/step - loss: 3.8229\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6253\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4601\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2944\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1298\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9684\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.8104\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6550\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5007\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3452\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 395ms/step - loss: 6.5447\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0321\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.5237\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.0189\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5178\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0195\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5257\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0371\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5557\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.0865\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 393ms/step - loss: 2.5481\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2182\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9028\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.6129\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3662\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1863\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0829\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0422\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0382\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0474\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 7.8199\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 7.2190\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.6233\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.0325\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.4491\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8846\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3516\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.8752\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.4877\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.1938\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 370ms/step - loss: 6.4384\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9736\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5107\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0505\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.5927\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1385\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.6866\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2377\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7939\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3577\n",
      "1/1 [==============================] - 0s 302ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.5945\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.4545\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.3222\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.1784\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.0336\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.9140\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.7685\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.6345\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.4925\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.3667\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.6839\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 4.5013\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.2927\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.1268\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.9381\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.7531\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.5743\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.3825\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.2062\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.0164\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.3272\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.2108\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.0811\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.9199\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.8304\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.7077\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.5651\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.4548\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.3726\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.2651\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.9665\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.7861\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.6376\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.4771\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.3162\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.1566\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.9876\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.8357\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.6796\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.5220\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.7222\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.5357\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.3651\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 4.1753\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.0251\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.8550\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.7225\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.5723\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.3987\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 3.2704\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 406ms/step - loss: 3.7639\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.9009\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6332\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4906\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3621\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2430\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1339\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0366\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9525\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8860\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 1.3312\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2763\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3614\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3599\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9642\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0512\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7955\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0978\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8459\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0228\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 461ms/step - loss: 1.0268\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9569\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8999\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8606\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8288\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8073\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7887\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7713\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7561\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.7439\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 378ms/step - loss: 1.1805\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0448\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1666\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2761\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3840\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4648\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1512\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4281\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0770\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4403\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 377ms/step - loss: 3.9392\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2252\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5095\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7465\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9400\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8157\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6938\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.6437\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6920\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5782\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 2.1462\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.9521\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1622\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0115\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9396\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.4442\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8624\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8030\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2164\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8102\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 340ms/step - loss: 3.6969\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1177\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8668\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0414\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3952\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8435\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3963\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0792\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5354\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0639\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 376ms/step - loss: 3.1518\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1259\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9294\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7491\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8802\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0309\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0638\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8330\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7435\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9383\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 362ms/step - loss: 15.3539\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.6765\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.3135\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 14.8143\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 14.0693\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.7993\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.7910\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 13.5580\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.5771\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.6028\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 397ms/step - loss: 5.2191\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.4913\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.7602\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3278\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5200\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5499\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.1774\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9628\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9742\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0948\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 426ms/step - loss: 3.6248\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4716\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4551\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.2310\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.3404\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.8104\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8620\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.1816\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.1376\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9724\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 465ms/step - loss: 4.3351\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 3.9903\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.5564\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.7595\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.2387\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4519\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.0050\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4517\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.3799\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7236\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 421ms/step - loss: 2.5326\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.2579\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.1684\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.3211\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.4517\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9649\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7763\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0690\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.8725\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.7530\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 445ms/step - loss: 2.4514\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.8677\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 2.5988\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.3397\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3985\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4605\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1806\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9159\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2620\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7714\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 419ms/step - loss: 7.0078\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.6758\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.3167\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.6965\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.9481\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.1066\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.5106\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9025\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.0201\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.5099\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 401ms/step - loss: 21.7969\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 15.2738\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.2916\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.5086\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5883\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4803\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.2008\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0950\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5019\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0824\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 338ms/step - loss: 13.8271\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.7131\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.6344\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.0589\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7440\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1013\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3203\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5696\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1207\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0834\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 2.8722\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.4353\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.9440\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6999\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9163\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2527\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.6838\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9776\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7422\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3965\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 349ms/step - loss: 2.2784\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.3412\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.1887\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.9973\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0177\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.6580\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2474\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.8769\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7835\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6232\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 361ms/step - loss: 19.0023\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.3385\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.7592\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.7334\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2171\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0291\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.2713\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7735\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2023\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.5476\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 3.2990\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.0903\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.8845\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 1.8496\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.4980\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.6091\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.0140\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.3596\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.5169\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.0292\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 6.7066\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7.1697\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 7.7025\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 6.1704\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6.8186\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6.7718\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6.6263\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 5.6560\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 6.0996\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.9755\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 10.2051\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 9.7983\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 9.5171\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 10.1567\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 9.6797\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 9.6018\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.5474\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 9.3122\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 9.8997\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 8.9478\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.9164\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.4386\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.8297\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.9168\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 1.9671\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.1216\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.3316\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.1323\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 1.5821\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.8686\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.8002\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.8609\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 2.1556\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 3.7039\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 2.7155\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.9873\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 4.4781\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 3.3981\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 5.0083\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 2.9966\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 460ms/step - loss: 2.9467\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.1703\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2800\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.1034\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9646\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1035\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0642\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0868\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3096\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.8802\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 3.7982\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 22.4039\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2133\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.5284\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.2909\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.0829\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.5172\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5253\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0914\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2705\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 415ms/step - loss: 2.9629\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 27.9729\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0317\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.6748\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.9777\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.4735\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7588\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9424\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3681\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.9654\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 495ms/step - loss: 1.6852\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 15.9183\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.9292\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8388\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8413\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1354\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.2688\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.8290\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2530\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8205\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 431ms/step - loss: 5.8379\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 26.3566\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.7777\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.0633\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8051\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0014\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6838\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.4512\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9464\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.9281\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 379ms/step - loss: 0.7823\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2594\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0571\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6915\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6979\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7148\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1002\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0709\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 2.0525\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6779\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 381ms/step - loss: 8.2972\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.8101\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7595\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2687\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6637\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2945\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6068\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3082\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5572\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.3336\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 358ms/step - loss: 5.4935\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.3934\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7009\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9994\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9106\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.8358\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7851\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8116\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.2059\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0007\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 15.1894\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.3509\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.7320\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6711\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.4328\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.2586\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1121\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9800\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8671\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7736\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 343ms/step - loss: 2.1263\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.8890\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.6846\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.4971\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3252\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1705\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0421\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9536\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1029\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.5480\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 420ms/step - loss: 7.9066\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3849\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.8651\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.3488\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.8352\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 5.3229\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.8118\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 4.3003\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7893\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.2803\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s 374ms/step - loss: 1.9221\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3883\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.9438\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.7553\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8863\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0143\n",
      "Epoch 7/10\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(\n",
    "    estimator=keras_clf, \n",
    "    param_distributions=params, \n",
    "    scoring='f1_macro',  # we could use any appropriate sklearn metric here (i.e. accuracy, f1_micro, f1_macro)\n",
    "    n_iter=50, \n",
    "    cv=5)\n",
    "\n",
    "# In rare cases, you may find your model training results in exceeding python's default recursion limit.\n",
    "# If needed, you can increase this excersion limit by using the following code.\n",
    "#import sys\n",
    "#sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train,  verbose=1)\n",
    "\n",
    "# You can create 'call back' functions. These are functions that will be called at the \n",
    "# end of each epoch. There are a number of builtin functions created for this purpose, \n",
    "# one of which is EarlyStopping -- that, based on the parameters you give, will stop\n",
    "# the training process. This is useful when the algorithm is not making any significant\n",
    "# gains through further training. \n",
    "#earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "#callback = [earlystop]\n",
    "#_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0a57e0b2-de2a-4e68-8e6a-ffc14f956a43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.01,\n",
       " 'optimizer': 'adam',\n",
       " 'model__hidden_layer_sizes': (90,),\n",
       " 'model__dropout': 0,\n",
       " 'loss': 'binary_crossentropy',\n",
       " 'epochs': 10,\n",
       " 'batch_size': 20}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "902fd2c9-6c73-404d-b81e-4a9470f6d95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d29a676-3127-49bc-bc63-a4c1b7d59b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "best score 0.5185185185185185\n",
      "min loss 1.5137077569961548\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 96.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"best score {best_model.score(X_test, y_test)}\")\n",
    "print(f\"min loss {min(best_model.history_['loss'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "45b8739b-411e-4998-a866-74c60ebc2cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'loss': [5.119305610656738,\n",
       "              1.9255129098892212,\n",
       "              6.094133377075195,\n",
       "              1.5137077569961548,\n",
       "              1.574845314025879,\n",
       "              1.876033902168274,\n",
       "              1.7700855731964111,\n",
       "              4.957487106323242,\n",
       "              3.0840814113616943,\n",
       "              1.9829195737838745]})"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d79a1c9c-bc11-41bf-9121-801e322b3662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, best_model.predict(X_test))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e730f6ff-928e-443d-a05e-f3f839280b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    0.1333    0.2353        15\n",
      "           1     0.4800    1.0000    0.6486        12\n",
      "\n",
      "    accuracy                         0.5185        27\n",
      "   macro avg     0.7400    0.5667    0.4420        27\n",
      "weighted avg     0.7689    0.5185    0.4190        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, best_model.predict(X_test), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce00af7-3375-4759-b837-6e60b059fbde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
