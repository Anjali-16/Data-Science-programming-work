{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "296dd1d7-aace-4eaf-9fff-e0e2733ce9dd",
   "metadata": {},
   "source": [
    "# In this notebook i would like to demonstrate the MLP classifier and also high level API model Keras for my cryptotheraphy dataset and explore the results of cost metrics to see how well these models are performing to my dataset and compare with my previous model in Assignment-1 notebbok.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7db087-86c7-4fc7-ac35-32b6ce7f1023",
   "metadata": {},
   "source": [
    "# Description of the data set:\n",
    "\n",
    "The data set is about CRYPTOTHERAPHY ANALYSIS.This data set provides patients characterstics after the tratment the level of cancer.\n",
    "It states whether the cancer level is benign(1) or malignant(0). This data set contains the following attributes:\n",
    "1. SEX- It indicates the gender of the patient whetehrthe patient is a male or female.(1=male,2=female)\n",
    "2. AGE- It indicates the age of the patient.\n",
    "3. Time- This column indicates the time for the treatment in seconds.\n",
    "4. Number of warts- This column indicates the numbe rof warts that are grown on a patients body. ( Warts are skin growths caused by a virus. The virus infects the top layer of skin, causing it to grow rapidly.Warts can grow anywhere on your body. Most warts go away on their own, but they may come back.)\n",
    "5. Type : It indicates the type of wart. ( there are mainly three types of warts . 1,2,3 ( common warts, flat,filtform)\n",
    "6. Area: The composition of wart .\n",
    "7. Result of the tratment: It indicates the level of cancer after tratment.\n",
    "\n",
    "The target variable is Result of the tratment. It is a binary classifier. benign(1) or malignant(0).\n",
    "This data set is a classification type of problem.\n",
    "The data set contains the instances of the 90 patients that are obtained from the results of cryptotheraphy treatment.\n",
    "\n",
    "Source of the data set: It is taken from the Mashhad University of Medical Sciences, Mashhad, Iran. Fahime Khozeimeh, MD, Pouran Layegh, Professor of Dermatology and Roohallah Alizadehsani, PhD student and Mohamad Roshanzamir, PhD candidate.\n",
    "\n",
    "It is published in UCI MACHINE LEARNING REPOSITORY: https://archive.ics.uci.edu/ml/datasets/Cryotherapy+Dataset+\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f07d3a-bd80-44dd-9b4c-0f613e4f5526",
   "metadata": {},
   "source": [
    "# Business problem statement and its purpose:\n",
    "1. The analysis of this data set will identify the results of the cancer treatment. It is a health care industry domain.\n",
    "2. Purpose :  This will helps the to explore and draw some inferences that may help the people to undergo the Cryotherapic treatment.\n",
    "3. It also helps the crytotheraphists to see the sttaistics and how well their treatment serves the people. How they can improve the level of treatment.\n",
    "4. It also helps to identify what age groups of patients  the treatment is getting malignant and what age groups of people is getting benign \n",
    "5. In this notebook I would like to do data preprocessing that is ready to apply modleing .\n",
    "6. For this assignment I would like to use the following algorithms (Discussed in class so far) to identify how well my models are trained and see how it performs of test data and if a new data is given it can able to predict the likelihood of results of level of tretament .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4766dee6-2762-47b6-8b1b-d3e8b878fe24",
   "metadata": {},
   "source": [
    "## In my assignment-1 data prep notebook I already done the data preprocessing and saved them to files and I am using those files directly to load and fit my models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926c9bdb-cae3-43fb-b4a2-6675bb81ceed",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59640443-c5a7-4075-b6f5-cd25dab735b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8645c8-0841-49f3-92d8-8844d2b5f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911c82e9-0a91-4706-874d-8dbc3b578bac",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09d7c2ca-ff0c-4178-8684-ec1423c74161",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"crypto_data_train_X.csv\")\n",
    "X_test = pd.read_csv(\"crypto_data_test_X.csv\")\n",
    "y_train = pd.read_csv(\"crypto_data_train_y.csv\")\n",
    "y_test = pd.read_csv(\"crypto_data_test_y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96f64092-f4b6-4fae-8b9e-a8c90d78b413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b6a59-6686-41ec-b1c0-891afbd63176",
   "metadata": {},
   "source": [
    "# Neural Network with MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6da4e6fb-fdee-45e1-8898-cfa3393ada1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 250 ms\n",
      "Wall time: 176 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(40,30,20), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "197cea45-4191-4276-b53f-5da7cedd08c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb532cd4-0440-41e2-b465-6210b0eb90e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.67      0.77        15\n",
      "           1       0.69      0.92      0.79        12\n",
      "\n",
      "    accuracy                           0.78        27\n",
      "   macro avg       0.80      0.79      0.78        27\n",
      "weighted avg       0.81      0.78      0.78        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a0fbf1-04bf-4b81-8f23-a7b2d2fe1caf",
   "metadata": {},
   "source": [
    "# F1 metric using Randomised search cv for neural net using MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3900ef64-4e8a-44d4-93ed-5df40c4bcd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.01, 'learning_rate': 'invscaling', 'hidden_layer_sizes': (60, 40, 20), 'alpha': 0.2, 'activation': 'logistic'}\n",
      "CPU times: total: 2.03 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "score_measure = make_scorer(f1_score , average='macro')\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (90,), (80,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cfcbf9d9-cad4-4bbd-92c3-6ce2986c7d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.73      0.85        15\n",
      "           1       0.75      1.00      0.86        12\n",
      "\n",
      "    accuracy                           0.85        27\n",
      "   macro avg       0.88      0.87      0.85        27\n",
      "weighted avg       0.89      0.85      0.85        27\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552d7c3e-4160-47e7-a137-8d3446c9eb2a",
   "metadata": {},
   "source": [
    "#  grid search cv for neural net for MLP classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0b40b1fc-d4f0-4bd4-9bfb-5836f77213a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'tanh', 'alpha': 0.7, 'hidden_layer_sizes': (30,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.01, 'max_iter': 5000, 'solver': 'adam'}\n",
      "CPU times: total: 578 ms\n",
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = make_scorer(f1_score , average='macro')\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df9fb5e8-ba34-4869-a607-acb012b7e946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.73      0.81        15\n",
      "           1       0.73      0.92      0.81        12\n",
      "\n",
      "    accuracy                           0.81        27\n",
      "   macro avg       0.82      0.82      0.81        27\n",
      "weighted avg       0.84      0.81      0.81        27\n",
      "\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d011ba-fce9-4f2c-a46f-418c9ab99e90",
   "metadata": {},
   "source": [
    "# Using Keras neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed97fbe2-ed25-44e6-9197-1b67315fb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fd26664-561b-456f-8e19-b898b8f1875c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 42.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create model stucture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(6))\n",
    "model.add(keras.layers.Dense(30, activation='relu'))\n",
    "model.add(keras.layers.Dense(30, activation='relu'))\n",
    "model.add(keras.layers.Dense(30, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) # final layer, 1 categories\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def f1_score(y_test, y_pred):\n",
    "    \"\"\"\n",
    "    Custom metric for F1 score.\n",
    "    \n",
    "    Arguments:\n",
    "    y_test -- true labels\n",
    "    y_pred -- predicted labels\n",
    "    \n",
    "    Returns:\n",
    "    f1_score -- F1 score\n",
    "    \"\"\"\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    tp = K.sum(K.round(K.clip(y_test * y_pred, 0, 1)))\n",
    "    fp = K.sum(K.round(K.clip(y_pred - y_test, 0, 1)))\n",
    "    fn = K.sum(K.round(K.clip(y_test - y_pred, 0, 1)))\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "    return f1_score\n",
    "\n",
    "# compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1_score])\n",
    "\n",
    "# if you want to overide the defaults for the optimizer....\n",
    "#adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0e535ee-2de3-41eb-ae3f-12bc22afb2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function f1_score at 0x000001FEE095FE50> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function f1_score at 0x000001FEE095FE50>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function f1_score at 0x000001FEE095FE50> and will run it as-is.\n",
      "Cause: Unable to locate the source code of <function f1_score at 0x000001FEE095FE50>. Note that functions defined in certain environments, like the interactive Python shell, do not expose their source code. If that is the case, you should define them in a .py source file. If you are certain the code is graph-compatible, wrap the call using @tf.autograph.experimental.do_not_convert. Original error: could not get source code\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "7/7 [==============================] - 1s 51ms/step - loss: 1.2301 - f1_score: 0.7642 - val_loss: 0.9901 - val_f1_score: 0.5150\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.8811 - f1_score: 0.2637 - val_loss: 0.8081 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7406 - f1_score: 0.3682 - val_loss: 0.7713 - val_f1_score: 0.5150\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6609 - f1_score: 0.7205 - val_loss: 0.8770 - val_f1_score: 0.5150\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6730 - f1_score: 0.7772 - val_loss: 0.7453 - val_f1_score: 0.5150\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6004 - f1_score: 0.7296 - val_loss: 0.7197 - val_f1_score: 0.5507\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.5960 - f1_score: 0.6352 - val_loss: 0.7443 - val_f1_score: 0.5516\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5704 - f1_score: 0.7868 - val_loss: 0.7346 - val_f1_score: 0.6190\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5596 - f1_score: 0.6519 - val_loss: 0.7661 - val_f1_score: 0.6190\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5423 - f1_score: 0.6805 - val_loss: 0.6980 - val_f1_score: 0.7091\n",
      "CPU times: total: 4.2 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=10, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b65a4442-460a-4dbc-9e53-daaba1ddfa81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6576361060142517, 0.3157894015312195]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea84c333-a5b5-4b20-b5b5-7994fd9f6f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.66\n",
      "f1_score: 31.58%\n"
     ]
    }
   ],
   "source": [
    "# let's format this into a better output...\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606c7b8-51ba-4363-a381-c27d4f38528a",
   "metadata": {},
   "source": [
    "# Wide and Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa9d9377-64e7-4386-9fee-eeb9049c6a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=6))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(100, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "421c25bc-5126-47a8-b5cd-1dcb5fc2d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[f1_score])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0df67d0-9d6c-4cc2-abc1-0e825ce2a049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7/7 [==============================] - 1s 52ms/step - loss: 8.1214 - f1_score: 0.2658 - val_loss: 1.0076 - val_f1_score: 0.0000e+00\n",
      "Epoch 2/10\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.0248 - f1_score: 0.4486 - val_loss: 2.2648 - val_f1_score: 0.6127\n",
      "Epoch 3/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9955 - f1_score: 0.5268 - val_loss: 1.6088 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.2522 - f1_score: 0.2492 - val_loss: 1.4346 - val_f1_score: 0.5238\n",
      "Epoch 5/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9337 - f1_score: 0.7880 - val_loss: 0.6737 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6570 - f1_score: 0.3912 - val_loss: 0.7684 - val_f1_score: 0.5833\n",
      "Epoch 7/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6462 - f1_score: 0.7225 - val_loss: 0.7141 - val_f1_score: 0.3148\n",
      "Epoch 8/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6263 - f1_score: 0.6413 - val_loss: 0.7706 - val_f1_score: 0.5833\n",
      "Epoch 9/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5646 - f1_score: 0.6637 - val_loss: 0.6189 - val_f1_score: 0.4333\n",
      "Epoch 10/10\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5625 - f1_score: 0.6925 - val_loss: 0.6470 - val_f1_score: 0.6389\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33c16ddc-01e6-461d-b13b-586cf8063c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.646960437297821, 0.615384578704834]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c37e26d-1cfd-4fed-93db-ed5ed10d7303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.65\n",
      "f1_score: 61.54%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc398f-2377-4cf2-9ca2-6ece3b2eadd0",
   "metadata": {},
   "source": [
    "# RandomGridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ef32508-d256-4bb1-a2e1-84654d7cb0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = f1_score\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=6)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotNormal(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    ann.compile(loss = 'binary_crossentropy', metrics = [f1_score])\n",
    "    return ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8459542-b458-4ab2-af03-98090d3e4d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=7,\n",
    "    dropout = 0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67b1ef15-6320-44d0-bf70-6bb91bb5fe9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.01],\n",
    "    'model__hidden_layer_sizes': [(700,),(700,500)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[2000],\n",
    "    'epochs':[2000],\n",
    "    'optimizer':[\"adam\"]\n",
    "}\n",
    "keras_clf.get_params().keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "608dd7e8-f2c1-4753-bde0-fcb330a22bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='accuracy', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1da18cfd-be8f-4027-9955-21f6468335ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.01,\n",
       " 'optimizer': 'adam',\n",
       " 'model__hidden_layer_sizes': (700, 500),\n",
       " 'model__dropout': 0.1,\n",
       " 'epochs': 2000,\n",
       " 'batch_size': 2000}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "675a1b49-35a6-447d-8d3a-e44f29ab2218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer__learning_rate': 0.01, 'optimizer': 'adam', 'model__hidden_layer_sizes': (700, 500), 'model__dropout': 0.1, 'epochs': 2000, 'batch_size': 2000}\n"
     ]
    }
   ],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f49fb30-3d37-4b4c-a4b9-2e05c7dfac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.60      0.64        15\n",
      "           1       0.57      0.67      0.62        12\n",
      "\n",
      "    accuracy                           0.63        27\n",
      "   macro avg       0.63      0.63      0.63        27\n",
      "weighted avg       0.64      0.63      0.63        27\n",
      "\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 108 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = best_net.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1b18eb-3825-4927-9305-6741780c6171",
   "metadata": {},
   "source": [
    "# Analysis:\n",
    "1. As per the assignment I have developed Neural network model using MLP classifier and also Keras API.\n",
    "2. For my cryptotheraphy dataset the results for Neural network using MLP classifier and Keras API are as follows.\n",
    "3. Remember here for my dataset I am considering F1 score as best metric which I argued in assignment-1.\n",
    "4. Lets compare the f1 scores for neural network model using MLP classifier and keras api before and after hyper parameter tuning.\n",
    "5. For keras API i intially I started with less neurons and then increased the neurons.\n",
    "6. Lets compare:\n",
    "                                         \n",
    "                                         \n",
    "        MLP CLASSIFIER  Before tuning    79   \n",
    "        \n",
    "        After tuning  Random search      86 \n",
    "        \n",
    "                      Grid search        81\n",
    "        \n",
    "        Keras with less neurons         31.58  \n",
    "        \n",
    "        Keras with more neurons         61.54 \n",
    "        \n",
    "        After tuning  it is 64%\n",
    "                                      \n",
    " I tried selu, elu, with he_normal,lecun_normal around 2 days some times it is giving 78, 85 and some times it is underfitting.\n",
    "    \n",
    "How ever among these both MLP classifier after hyper parameter tuning is having best results of about 86 percent.\n",
    "    \n",
    " Now comparing this with my old assignment 1 models Among my previous models decision tree is best model with a f1 score value of about 92.11.\n",
    "    \n",
    " So, deciison tree is performing well when compared to the neural networks.\n",
    "    \n",
    " \n",
    " So, I can say that for my data set F1 score is best metric and Deciison tree model is best model (As far as the models which i run till now from      assignment 1, assignment 2)\n",
    "                                         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
